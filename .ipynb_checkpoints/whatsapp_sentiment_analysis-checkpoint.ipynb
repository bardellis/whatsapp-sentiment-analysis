{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8863a50",
   "metadata": {},
   "source": [
    "# Whatsapp group sentiment analysis\n",
    "In this work I make a model to know the polarity of the sentiments of the messages in a whatsapp group.\n",
    "\n",
    "In the development of the work I will analyse different aspects of the dynamics of the group, highlighting the activity of the different users, the type of messages and the topics that were discussed with their corresponding polarity.\n",
    "\n",
    "this is my final work of the data analytic bootcamp, and i decided to do this work because i believe that the spontaneity and quantity of the messages are an extremely valuable resource to know the opinion of the people about relevant topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea776ef",
   "metadata": {},
   "source": [
    "# 1. Import basic libraries & read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b529644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import timedelta\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "199167c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your text file\n",
    "file_path = 'WhatsApp.txt'\n",
    "\n",
    "# Initialize lists to store parsed information\n",
    "dates = []\n",
    "times = []\n",
    "senders = []\n",
    "messages = []\n",
    "\n",
    "# Define a regular expression pattern to extract information\n",
    "pattern = re.compile(r'(\\d+/\\d+/\\d+ \\d+:\\d+) - ([^:]+): (.+)')\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    # Iterate through each line in the file\n",
    "    for line in file:\n",
    "        # Use the regular expression to match and extract information\n",
    "        match = pattern.match(line.strip())\n",
    "        if match:\n",
    "            # Extract date, time, sender, and message\n",
    "            datetime_str, sender, message = match.groups()\n",
    "\n",
    "            # Convert date and time to a datetime object\n",
    "            datetime_obj = datetime.strptime(datetime_str, '%d/%m/%y %H:%M')\n",
    "\n",
    "            # Append information to the respective lists\n",
    "            dates.append(datetime_obj.date())\n",
    "            times.append(datetime_obj.time())\n",
    "            senders.append(sender)\n",
    "            messages.append(message)\n",
    "\n",
    "# Create a DataFrame for easier analysis\n",
    "df = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Time': times,\n",
    "    'Sender': senders,\n",
    "    'Message': messages\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a76592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the nickname mapping from CSV into a DataFrame\n",
    "nickname_mapping = pd.read_csv('sender_nickname.csv')\n",
    "\n",
    "# Create a mapping dictionary from 'Full Name' to 'Nickname'\n",
    "name_mapping_dict = dict(zip(nickname_mapping['Full Name'], nickname_mapping['Nickname']))\n",
    "\n",
    "# Replace values in the 'Sender' column of the original DataFrame (df) using the mapping\n",
    "df['Sender'] = df['Sender'].replace(name_mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6806991e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>01:29:00</td>\n",
       "      <td>Yames</td>\n",
       "      <td>&lt;Multimedia omitido&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>04:04:00</td>\n",
       "      <td>Yames</td>\n",
       "      <td>&lt;Multimedia omitido&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>04:05:00</td>\n",
       "      <td>Eze</td>\n",
       "      <td>Schames ü§¶‚Äç‚ôÇÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>04:29:00</td>\n",
       "      <td>Delca</td>\n",
       "      <td>Jajajajajajaja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>04:30:00</td>\n",
       "      <td>Eze</td>\n",
       "      <td>&lt;Multimedia omitido&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time Sender               Message\n",
       "0  2021-02-02  01:29:00  Yames  <Multimedia omitido>\n",
       "1  2021-02-02  04:04:00  Yames  <Multimedia omitido>\n",
       "2  2021-02-02  04:05:00    Eze          Schames ü§¶‚Äç‚ôÇÔ∏è\n",
       "3  2021-02-02  04:29:00  Delca        Jajajajajajaja\n",
       "4  2021-02-02  04:30:00    Eze  <Multimedia omitido>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058b21a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c6668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bcd936e",
   "metadata": {},
   "source": [
    "#  2.Data Preparation and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e9e9b",
   "metadata": {},
   "source": [
    "## Understanding the data\n",
    "Before we start cleaning the dataset, we need to understand the business and the data structure\n",
    "* we can see that the dataset has 3 columns (date, sender and message)\n",
    "* we have 39972 messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3595e871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39972, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataframe shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7191e619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Time', 'Sender', 'Message'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataframe columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a23324e",
   "metadata": {},
   "source": [
    "## Cleaning messages \n",
    "This step is critical in the sentiment analysis process - we need to make sure that the words and messages make sense to the model. It is about ensuring that the messages reach the sentiment analysis with meaning and do not cause confusion.\n",
    "To achieve this, we need to clean the messages of jargon, including all kinds of onomatopoeias, emogis and multimedia so common in whatsapp communication. \n",
    "Stop words will be cleaned up later. They are not applicable at the moment because Bert Multilanguage needs them to interpret the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5489723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column to categorize MessageCount\n",
    "msg_counts = df['Message'].value_counts().reset_index()\n",
    "msg_counts.columns = ['Message','repetition']\n",
    "msg_counts['repetition_cat'] = pd.cut(msg_counts['repetition'], bins=[0, 1, 2, 3, float('inf')],\n",
    "                                       labels=['1 msg', '2 msg', '3 msg', '>3 msg'])\n",
    "\n",
    "# Function to count words in a given text\n",
    "def count_words(text):\n",
    "    \"\"\"\n",
    "    Count the number of words in a given text.\n",
    "    Parameters:\n",
    "        text (str): The input text.\n",
    "    Returns:\n",
    "        int: The number of words in the text.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return len(text.split())\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to the 'text' column and create a new 'word_count' column\n",
    "msg_counts['word_count'] = msg_counts['Message'].apply(lambda x: count_words(x))\n",
    "\n",
    "msg_counts['word_count_cat'] = pd.cut(\n",
    "    msg_counts['word_count'],\n",
    "    bins=[0, 5, 10, float('inf')],\n",
    "    labels=['1-4 words', '5-10 words', '>10 words']\n",
    ")\n",
    "\n",
    "msg_counts['word_count_group'] = pd.cut(\n",
    "    msg_counts['word_count'],\n",
    "    bins=[0, 10, float('inf')],\n",
    "    labels=['short msg', 'regular msg']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e028ba4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word_count_group</th>\n",
       "      <th>short msg</th>\n",
       "      <th>regular msg</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repetition_cat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 msg</th>\n",
       "      <td>16721</td>\n",
       "      <td>4310</td>\n",
       "      <td>21031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 msg</th>\n",
       "      <td>722</td>\n",
       "      <td>6</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 msg</th>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;3 msg</th>\n",
       "      <td>17901</td>\n",
       "      <td>0</td>\n",
       "      <td>17901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>35656</td>\n",
       "      <td>4316</td>\n",
       "      <td>39972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "word_count_group  short msg  regular msg  Total\n",
       "repetition_cat                                 \n",
       "1 msg                 16721         4310  21031\n",
       "2 msg                   722            6    728\n",
       "3 msg                   312            0    312\n",
       ">3 msg                17901            0  17901\n",
       "Total                 35656         4316  39972"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pivot table with totals\n",
    "result_pivot = pd.pivot_table(\n",
    "    msg_counts,\n",
    "    values='repetition',\n",
    "    index='repetition_cat',\n",
    "    columns=['word_count_group'],\n",
    "    aggfunc='sum',\n",
    "    fill_value=0,\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "\n",
    "result_pivot_filtered = result_pivot.loc[:, (result_pivot != 0).any(axis=0)]\n",
    "\n",
    "# Display the filtered result_pivot\n",
    "result_pivot_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4426fa3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word_count_cat</th>\n",
       "      <th>1-4 words</th>\n",
       "      <th>5-10 words</th>\n",
       "      <th>&gt;10 words</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repetition_cat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 msg</th>\n",
       "      <td>11056</td>\n",
       "      <td>5665</td>\n",
       "      <td>4310</td>\n",
       "      <td>21031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 msg</th>\n",
       "      <td>708</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 msg</th>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;3 msg</th>\n",
       "      <td>17901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>29977</td>\n",
       "      <td>5679</td>\n",
       "      <td>4316</td>\n",
       "      <td>39972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "word_count_cat  1-4 words  5-10 words  >10 words  Total\n",
       "repetition_cat                                         \n",
       "1 msg               11056        5665       4310  21031\n",
       "2 msg                 708          14          6    728\n",
       "3 msg                 312           0          0    312\n",
       ">3 msg              17901           0          0  17901\n",
       "Total               29977        5679       4316  39972"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pivot table with totals\n",
    "result_pivot = pd.pivot_table(\n",
    "    msg_counts,\n",
    "    values='repetition',\n",
    "    index='repetition_cat',\n",
    "    columns=['word_count_cat'],\n",
    "    aggfunc='sum',\n",
    "    fill_value=0,\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "\n",
    "result_pivot_filtered = result_pivot.loc[:, (result_pivot != 0).any(axis=0)]\n",
    "\n",
    "# Display the filtered result_pivot\n",
    "result_pivot_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cfaee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c37d3c2",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Short messages of 1 to 4 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ff17e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>repetition</th>\n",
       "      <th>repetition_cat</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cat</th>\n",
       "      <th>word_count_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;Multimedia omitido&gt;</td>\n",
       "      <td>15400</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>2</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Se elimin√≥ este mensaje.</td>\n",
       "      <td>275</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>4</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jajajaj</td>\n",
       "      <td>204</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>1</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jajaja</td>\n",
       "      <td>129</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>1</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jajajaja</td>\n",
       "      <td>89</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>1</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ü§≠</td>\n",
       "      <td>60</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>1</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Si</td>\n",
       "      <td>47</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>1</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Schames</td>\n",
       "      <td>44</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>1</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cupelli</td>\n",
       "      <td>37</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>1</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>üëèüëèüëèüëè</td>\n",
       "      <td>37</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>1</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Se√±ore</td>\n",
       "      <td>35</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>1</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jajajajaja</td>\n",
       "      <td>35</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>1</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Schames...</td>\n",
       "      <td>32</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>1</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>üëèüëèüëè</td>\n",
       "      <td>29</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>1</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>null</td>\n",
       "      <td>29</td>\n",
       "      <td>&gt;3 msg</td>\n",
       "      <td>1</td>\n",
       "      <td>1-4 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Message  repetition repetition_cat  word_count  \\\n",
       "0       <Multimedia omitido>       15400         >3 msg           2   \n",
       "1   Se elimin√≥ este mensaje.         275         >3 msg           4   \n",
       "2                    Jajajaj         204         >3 msg           1   \n",
       "3                     Jajaja         129         >3 msg           1   \n",
       "4                   Jajajaja          89         >3 msg           1   \n",
       "5                          ü§≠          60         >3 msg           1   \n",
       "6                         Si          47         >3 msg           1   \n",
       "7                    Schames          44         >3 msg           1   \n",
       "8                    Cupelli          37         >3 msg           1   \n",
       "9                       üëèüëèüëèüëè          37         >3 msg           1   \n",
       "10                    Se√±ore          35         >3 msg           1   \n",
       "11                Jajajajaja          35         >3 msg           1   \n",
       "12                Schames...          32         >3 msg           1   \n",
       "13                       üëèüëèüëè          29         >3 msg           1   \n",
       "14                      null          29         >3 msg           1   \n",
       "\n",
       "   word_count_cat word_count_group  \n",
       "0       1-4 words        short msg  \n",
       "1       1-4 words        short msg  \n",
       "2       1-4 words        short msg  \n",
       "3       1-4 words        short msg  \n",
       "4       1-4 words        short msg  \n",
       "5       1-4 words        short msg  \n",
       "6       1-4 words        short msg  \n",
       "7       1-4 words        short msg  \n",
       "8       1-4 words        short msg  \n",
       "9       1-4 words        short msg  \n",
       "10      1-4 words        short msg  \n",
       "11      1-4 words        short msg  \n",
       "12      1-4 words        short msg  \n",
       "13      1-4 words        short msg  \n",
       "14      1-4 words        short msg  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_counts[\n",
    "    (msg_counts['word_count_cat']=='1-4 words') & \n",
    "    (msg_counts['repetition_cat'] !='1 msg')\n",
    "].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecad4eb",
   "metadata": {},
   "source": [
    "Short messages have particular characteristics, they appear very often because they are brief and it is important to understand their nature given that most of them are short answers that have no meaning of their own, they are also used to make comments with double meaning (ironies) and also the use of signs or forms that are not understandable by the model.\n",
    "* multimedia messages notes\n",
    "* deleted messages notes\n",
    "* slang or jargon\n",
    "* use of marks and letters (alphabetic characters) to write onomatopoeias (Jajajaja, Jajaj, etc...)\n",
    "* words with double meanings.\n",
    "* emogis on the other hand has to be analysed separately\n",
    "* null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9dc6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c030beb",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Replace notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04012710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_msg_to_replace(text, elements_to_replace):\n",
    "    if isinstance(text, str):\n",
    "        for element in elements_to_replace:\n",
    "            text = text.replace(element, '')\n",
    "        return text.strip().lower()\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "message_to_replace = [\n",
    "    ('<Multimedia omitido>'),\n",
    "    ('Se elimin√≥ este mensaje.'),\n",
    "    ('ubicaci√≥n en tiempo real compartida'),\n",
    "    ('Eliminaste este mensaje.'),\n",
    "    ('null'),\n",
    "    ('\\n'),\n",
    "]\n",
    "\n",
    "# Apply the clean_words_to_replace function to the 'Message' column\n",
    "df['clean_msg'] = df['Message'].apply(lambda x: clean_msg_to_replace(x, message_to_replace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe72a816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_msg\n",
       "              15741\n",
       "jajajaj         210\n",
       "jajaja          157\n",
       "jajajaja        103\n",
       "ü§≠                60\n",
       "si               48\n",
       "jajajajaja       47\n",
       "schames          45\n",
       "cupelli          37\n",
       "üëèüëèüëèüëè             37\n",
       "se√±ore           35\n",
       "jaja             35\n",
       "schames...       32\n",
       "üëèüëèüëè              29\n",
       "cupelli...       28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_msg'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bfa08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1f74d91",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Replace emoticons and onomatopoeias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1f9d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_regex_patterns(text, regex_patterns):\n",
    "    if isinstance(text, str):\n",
    "        for pattern, replacement in regex_patterns:\n",
    "            text = re.sub(pattern, replacement, text)\n",
    "        return text\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "# List of regex patterns and replacements\n",
    "words_to_replace = [\n",
    "    (r'[^\\w\\s]|_', ''),          # Replace everything that is not an alphabetical string, including emojis\n",
    "    (r'http\\S+', ''),            # Remove URLs\n",
    "    (r'[0-9]+',''),               # Remove numbers\n",
    "    (r'\\s+', ' '),               # Replace multiple whitespaces with a single space\n",
    "    (r'^\\d+$',''),               # Replace strings consisting entirely of digits\n",
    "    (r'([a-zA-Z])\\1\\1', '\\\\1'),  # Replace consecutive identical characters with a single character\n",
    "]\n",
    "\n",
    "# List of regex patterns and replacements\n",
    "other_words_to_replace = [\n",
    "    (r'\\!{2,}', '!'),            # Replace repetition of !!! with !\n",
    "    (r'\\!', ''),                 # Remove !\n",
    "    (r'\\?{2,}', '?'),            # Replace repetition of ??? with ?\n",
    "    (r'\\.{2,}', ''),             # Remove repetition of ...\n",
    "    (r'^\\?\\s*$', ''),            # Remove ? to treate it as emoji\n",
    "    (r'^\\!\\s*$', ''),            # Remove ! to treate it as emoji\n",
    "    (r'^:\\-\\)$', ''),            # Remove :-) to treate it as emoji\n",
    "    (r'^;\\-\\)$', ''),            # Remove ;-) to treate it as emoji\n",
    "    (r'\\b(?:j[aj]*a[aj]*j[aj]*|ja(?:j[aj]*a[aj]*)*|ja(?:j[ak]*a[aj]*)*|ja+)\\b', ''),  # Remove repetition of ja = :)\n",
    "    (r'\\b(?:j[ej]*e[ej]*j[ej]*|je(?:j[ej]*e[ej]*)*)\\b', ''),                          # Remove repetition of je = :)\n",
    "    (r'\\b(?:j[oj]*o[oj]*j[oj]*|jo(?:j[oj]*o[oj]*)*|jo(?:j[ok]*o[oj]*)*|jo+)\\b', ''),  # Remove repetition of jo = :)\n",
    "    (r'\\b(?:j[uj]*u[uj]*j[uj]*|ju(?:j[uj]*u[uj]*)*|ju(?:j[uk]*u[uj]*)*|ju+)\\b', ''),  # Remove repetition of ju = :)\n",
    "    (r'\\b(jiji|jijij)\\b', ''),                                                        # Remove repetition of ji = :) \n",
    "]\n",
    "\n",
    "# Apply the function to the 'clean_msg' column\n",
    "df['clean_msg'] = df['clean_msg'].apply(lambda x: apply_regex_patterns(x, words_to_replace))\n",
    "df['clean_msg'] = df['clean_msg'].apply(lambda x: apply_regex_patterns(x, other_words_to_replace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f764b9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_msg\n",
       "                18366\n",
       "schames            96\n",
       "cupelli            70\n",
       "si                 54\n",
       "se√±ore             35\n",
       "no                 33\n",
       "feliz cumple       32\n",
       "loras              31\n",
       "muy bueno          30\n",
       "loro               27\n",
       "gracias            27\n",
       "                   26\n",
       "exacto             24\n",
       "inadi              19\n",
       "totalmente         18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_msg'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229a44af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38d390da",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Replace short messages with doble meaning\n",
    "At this point I reemploy the short messages with double meanings by a phrase that replaces the real meaning of the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "170e3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_patterns(series, patterns):\n",
    "    for pattern, replacement in patterns:\n",
    "        series = series.str.replace(pattern, replacement, regex=True, flags=re.IGNORECASE)\n",
    "    return series\n",
    "\n",
    "word_replacements = pd.read_csv('word_replacements.csv')\n",
    "word_replacements_list = list(zip(word_replacements['Pattern'], word_replacements['Replacement']))\n",
    "\n",
    "cleaned_replacements_list = [\n",
    "    (rf'^\\s*{str(pattern).replace(\"nan\", \"\")}\\s*$', rf'{str(replacement).replace(\"nan\", \"\")}')\n",
    "    for pattern, replacement in word_replacements_list\n",
    "]\n",
    "\n",
    "df['clean_msg'] = apply_patterns(df['clean_msg'], cleaned_replacements_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd3e8d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_msg\n",
       "                       18475\n",
       "(risa)                   435\n",
       "estoy de acuerdo         175\n",
       "me gust√≥ eso             166\n",
       "me sorprende             158\n",
       "confirmo que si           91\n",
       "si                        79\n",
       "no estoy de acuerdo       67\n",
       "no me gusta eso           58\n",
       "confirmo que no           51\n",
       "gracias                   38\n",
       "feliz cumple              32\n",
       "me gusta eso              28\n",
       "                          26\n",
       "y si                      15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_msg'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ae5fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79ad9265",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Replace other words and marks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2867848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_replacements(df, patterns):\n",
    "    for pattern, replacement in patterns:\n",
    "        df['clean_msg'] = df['clean_msg'].str.replace(pattern, replacement, regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "# Define your replacement patterns\n",
    "replacement_patterns = [\n",
    "    (r'^Bata\\s+\\w+$', '(risa)'),\n",
    "    (r'^Basta\\s+\\w+$', '(risa)'),\n",
    "    (r'^y( si)+$', 'confirmo que si'),\n",
    "    (r'\\b(gracias)+\\b', 'gracias'),\n",
    "    (r'\\bgracias+\\b', 'gracias'),\n",
    "    (r'^Ok\\.?\\s*$', 'estoy de acuerdo'),\n",
    "    (r'^se+\\s*$', 'estoy de acuerdo'),\n",
    "    (r'^Nah+\\s*$', 'me sorprende'),\n",
    "    (r'^No+\\s*$', 'me sorprende'),\n",
    "    (r'^\\s*a+migos\\s*$', 'amigos'),\n",
    "    (r'^\\s*([a-zA-Z])\\s*$', ''),\n",
    "    (r'^@\\d+$', ''),\n",
    "    (r'^\\s+$', ''),\n",
    "    (r'^\\s*', ''),\n",
    "    (r'^\\s*si\\b(?: si)+\\s*$', 'confirmo que si'),\n",
    "    (r'^(no\\s)+no$', 'confirmo que no'),\n",
    "    (r'b*chiques\\b', 'amigos'),\n",
    "    (r'b*o estoy crazy macaya\\b', ''),\n",
    "    (r'b*no es joda\\b', 'hablo enserio'),\n",
    "    (r'\\b(Perdon)+\\b', 'perd√≥n'),\n",
    "    (r'\\b(cumple+)+\\b', 'cumplea√±os'),    \n",
    "    (r'\\b(ojo+)+\\b', ''),\n",
    "    (r'\\b(epa+)+\\b', ''),\n",
    "    (r'\\b(apa+)+\\b', ''),\n",
    "]    \n",
    "\n",
    "# Apply replacements using the function\n",
    "apply_replacements(df, replacement_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50e135fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_msg\n",
       "                       18541\n",
       "(risa)                   471\n",
       "estoy de acuerdo         207\n",
       "me sorprende             186\n",
       "me gust√≥ eso             166\n",
       "confirmo que si          121\n",
       "si                        79\n",
       "no estoy de acuerdo       67\n",
       "no me gusta eso           58\n",
       "confirmo que no           55\n",
       "feliz cumplea√±os          51\n",
       "gracias                   38\n",
       "me gusta eso              28\n",
       "perd√≥n                    20\n",
       "muchas gracias            11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_msg'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df408f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1c099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4dfa802",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Short messages of 5 to 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c241dcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>repetition</th>\n",
       "      <th>repetition_cat</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cat</th>\n",
       "      <th>word_count_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Feliz cumple Santi !!! Abrazo grande!!!</td>\n",
       "      <td>2</td>\n",
       "      <td>2 msg</td>\n",
       "      <td>6</td>\n",
       "      <td>5-10 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Schames, no borres tus mensajes, dec√≠ lo que p...</td>\n",
       "      <td>2</td>\n",
       "      <td>2 msg</td>\n",
       "      <td>9</td>\n",
       "      <td>5-10 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Segal no se haga el gracioso</td>\n",
       "      <td>2</td>\n",
       "      <td>2 msg</td>\n",
       "      <td>6</td>\n",
       "      <td>5-10 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Ok, lo qu√© hay que saber:</td>\n",
       "      <td>2</td>\n",
       "      <td>2 msg</td>\n",
       "      <td>6</td>\n",
       "      <td>5-10 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Puede ser exactamente es verdad, o tambi√©n tod...</td>\n",
       "      <td>2</td>\n",
       "      <td>2 msg</td>\n",
       "      <td>10</td>\n",
       "      <td>5-10 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>Alguien que le avise a Luis</td>\n",
       "      <td>2</td>\n",
       "      <td>2 msg</td>\n",
       "      <td>6</td>\n",
       "      <td>5-10 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>No se haga el gracioso Segal</td>\n",
       "      <td>2</td>\n",
       "      <td>2 msg</td>\n",
       "      <td>6</td>\n",
       "      <td>5-10 words</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Message  repetition  \\\n",
       "302            Feliz cumple Santi !!! Abrazo grande!!!           2   \n",
       "399  Schames, no borres tus mensajes, dec√≠ lo que p...           2   \n",
       "406                       Segal no se haga el gracioso           2   \n",
       "444                          Ok, lo qu√© hay que saber:           2   \n",
       "477  Puede ser exactamente es verdad, o tambi√©n tod...           2   \n",
       "528                        Alguien que le avise a Luis           2   \n",
       "573                       No se haga el gracioso Segal           2   \n",
       "\n",
       "    repetition_cat  word_count word_count_cat word_count_group  \n",
       "302          2 msg           6     5-10 words        short msg  \n",
       "399          2 msg           9     5-10 words        short msg  \n",
       "406          2 msg           6     5-10 words        short msg  \n",
       "444          2 msg           6     5-10 words        short msg  \n",
       "477          2 msg          10     5-10 words        short msg  \n",
       "528          2 msg           6     5-10 words        short msg  \n",
       "573          2 msg           6     5-10 words        short msg  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_counts[\n",
    "    (msg_counts['word_count_cat']=='5-10 words') & \n",
    "    (msg_counts['repetition_cat'] !='1 msg')\n",
    "].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e730f60f",
   "metadata": {},
   "source": [
    "In this category of short messages (5-7 words) have a clear meaning and do not need modification, the repetitions are due to the fact that they are common ways of communicating. The use of multiple exclamation marks for emphasis is also observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a336be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac8e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75d37667",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Messages longer than 10 words\n",
    "As we could see in the pivot table at the beginning, there are messages of normal size that are duplicated. We can then confirm that these are duplicate messages, other than short messages...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3599934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>repetition</th>\n",
       "      <th>repetition_cat</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cat</th>\n",
       "      <th>word_count_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Muchachos, debo dejar el grupo por problemas p...</td>\n",
       "      <td>2</td>\n",
       "      <td>2 msg</td>\n",
       "      <td>74</td>\n",
       "      <td>&gt;10 words</td>\n",
       "      <td>regular msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>Los nuevos rufianes kirchneristas: DANIEL VILA...</td>\n",
       "      <td>2</td>\n",
       "      <td>2 msg</td>\n",
       "      <td>108</td>\n",
       "      <td>&gt;10 words</td>\n",
       "      <td>regular msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Totalmente negro. Sabias palabras. Una forma d...</td>\n",
       "      <td>2</td>\n",
       "      <td>2 msg</td>\n",
       "      <td>24</td>\n",
       "      <td>&gt;10 words</td>\n",
       "      <td>regular msg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Message  repetition  \\\n",
       "501  Muchachos, debo dejar el grupo por problemas p...           2   \n",
       "550  Los nuevos rufianes kirchneristas: DANIEL VILA...           2   \n",
       "609  Totalmente negro. Sabias palabras. Una forma d...           2   \n",
       "\n",
       "    repetition_cat  word_count word_count_cat word_count_group  \n",
       "501          2 msg          74      >10 words      regular msg  \n",
       "550          2 msg         108      >10 words      regular msg  \n",
       "609          2 msg          24      >10 words      regular msg  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_counts[\n",
    "    (msg_counts['word_count_cat']=='>10 words') & \n",
    "    (msg_counts['repetition_cat'] =='2 msg')\n",
    "].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d8207",
   "metadata": {},
   "source": [
    "These are normal sized messages, so there is no reason why the messages would be duplicates.\n",
    "This will most likely happen when messages are forwarded. This duplicate should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3779b20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72ff9b9c",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Drop regular messages duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "440a6dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Message</th>\n",
       "      <th>clean_msg</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>2021-04-11</td>\n",
       "      <td>19:13:00</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>Muchachos, debo dejar el grupo por problemas p...</td>\n",
       "      <td>muchachos debo dejar el grupo por problemas pe...</td>\n",
       "      <td>74</td>\n",
       "      <td>regular msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>18:37:00</td>\n",
       "      <td>Javo</td>\n",
       "      <td>Muchachos, debo dejar el grupo por problemas p...</td>\n",
       "      <td>muchachos debo dejar el grupo por problemas pe...</td>\n",
       "      <td>74</td>\n",
       "      <td>regular msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7251</th>\n",
       "      <td>2021-06-18</td>\n",
       "      <td>15:53:00</td>\n",
       "      <td>Matias</td>\n",
       "      <td>Puede ser exactamente es verdad, o tambi√©n tod...</td>\n",
       "      <td>puede ser exactamente es verdad o tambi√©n todo...</td>\n",
       "      <td>10</td>\n",
       "      <td>regular msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7411</th>\n",
       "      <td>2021-06-20</td>\n",
       "      <td>02:50:00</td>\n",
       "      <td>Matias</td>\n",
       "      <td>Puede ser exactamente es verdad, o tambi√©n tod...</td>\n",
       "      <td>puede ser exactamente es verdad o tambi√©n todo...</td>\n",
       "      <td>10</td>\n",
       "      <td>regular msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8010</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>21:26:00</td>\n",
       "      <td>Loro</td>\n",
       "      <td>Los nuevos rufianes kirchneristas: DANIEL VILA...</td>\n",
       "      <td>los nuevos rufianes kirchneristas daniel vila ...</td>\n",
       "      <td>108</td>\n",
       "      <td>regular msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11127</th>\n",
       "      <td>2021-08-24</td>\n",
       "      <td>21:51:00</td>\n",
       "      <td>Juan</td>\n",
       "      <td>Totalmente negro. Sabias palabras. Una forma d...</td>\n",
       "      <td>totalmente negro sabias palabras una forma de ...</td>\n",
       "      <td>24</td>\n",
       "      <td>regular msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11129</th>\n",
       "      <td>2021-08-24</td>\n",
       "      <td>21:54:00</td>\n",
       "      <td>Eze</td>\n",
       "      <td>Totalmente negro. Sabias palabras. Una forma d...</td>\n",
       "      <td>totalmente negro sabias palabras una forma de ...</td>\n",
       "      <td>24</td>\n",
       "      <td>regular msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11794</th>\n",
       "      <td>2021-09-07</td>\n",
       "      <td>14:14:00</td>\n",
       "      <td>Barde</td>\n",
       "      <td>Los nuevos rufianes kirchneristas: DANIEL VILA...</td>\n",
       "      <td>los nuevos rufianes kirchneristas daniel vila ...</td>\n",
       "      <td>108</td>\n",
       "      <td>regular msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26093</th>\n",
       "      <td>2023-02-20</td>\n",
       "      <td>17:06:00</td>\n",
       "      <td>Fede</td>\n",
       "      <td>Schames, no borres tus mensajes, dec√≠ lo que p...</td>\n",
       "      <td>schames no borres tus mensajes dec√≠ lo que pensas</td>\n",
       "      <td>9</td>\n",
       "      <td>regular msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26098</th>\n",
       "      <td>2023-02-20</td>\n",
       "      <td>18:46:00</td>\n",
       "      <td>Eze</td>\n",
       "      <td>Schames, no borres tus mensajes, dec√≠ lo que p...</td>\n",
       "      <td>schames no borres tus mensajes dec√≠ lo que pensas</td>\n",
       "      <td>9</td>\n",
       "      <td>regular msg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      Time  Sender  \\\n",
       "3114   2021-04-11  19:13:00  Garcia   \n",
       "3671   2021-04-16  18:37:00    Javo   \n",
       "7251   2021-06-18  15:53:00  Matias   \n",
       "7411   2021-06-20  02:50:00  Matias   \n",
       "8010   2021-06-29  21:26:00    Loro   \n",
       "11127  2021-08-24  21:51:00    Juan   \n",
       "11129  2021-08-24  21:54:00     Eze   \n",
       "11794  2021-09-07  14:14:00   Barde   \n",
       "26093  2023-02-20  17:06:00    Fede   \n",
       "26098  2023-02-20  18:46:00     Eze   \n",
       "\n",
       "                                                 Message  \\\n",
       "3114   Muchachos, debo dejar el grupo por problemas p...   \n",
       "3671   Muchachos, debo dejar el grupo por problemas p...   \n",
       "7251   Puede ser exactamente es verdad, o tambi√©n tod...   \n",
       "7411   Puede ser exactamente es verdad, o tambi√©n tod...   \n",
       "8010   Los nuevos rufianes kirchneristas: DANIEL VILA...   \n",
       "11127  Totalmente negro. Sabias palabras. Una forma d...   \n",
       "11129  Totalmente negro. Sabias palabras. Una forma d...   \n",
       "11794  Los nuevos rufianes kirchneristas: DANIEL VILA...   \n",
       "26093  Schames, no borres tus mensajes, dec√≠ lo que p...   \n",
       "26098  Schames, no borres tus mensajes, dec√≠ lo que p...   \n",
       "\n",
       "                                               clean_msg  word_count  \\\n",
       "3114   muchachos debo dejar el grupo por problemas pe...          74   \n",
       "3671   muchachos debo dejar el grupo por problemas pe...          74   \n",
       "7251   puede ser exactamente es verdad o tambi√©n todo...          10   \n",
       "7411   puede ser exactamente es verdad o tambi√©n todo...          10   \n",
       "8010   los nuevos rufianes kirchneristas daniel vila ...         108   \n",
       "11127  totalmente negro sabias palabras una forma de ...          24   \n",
       "11129  totalmente negro sabias palabras una forma de ...          24   \n",
       "11794  los nuevos rufianes kirchneristas daniel vila ...         108   \n",
       "26093  schames no borres tus mensajes dec√≠ lo que pensas           9   \n",
       "26098  schames no borres tus mensajes dec√≠ lo que pensas           9   \n",
       "\n",
       "      word_count_group  \n",
       "3114       regular msg  \n",
       "3671       regular msg  \n",
       "7251       regular msg  \n",
       "7411       regular msg  \n",
       "8010       regular msg  \n",
       "11127      regular msg  \n",
       "11129      regular msg  \n",
       "11794      regular msg  \n",
       "26093      regular msg  \n",
       "26098      regular msg  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_count'] = df['Message'].apply(lambda x: count_words(x))\n",
    "\n",
    "# Creating word_count_group column based on word_count\n",
    "df['word_count_group'] = pd.cut(\n",
    "    df['word_count'],\n",
    "    bins=[0, 7, float('inf')],\n",
    "    labels=['short msg', 'regular msg']\n",
    ")\n",
    "\n",
    "df[(df.duplicated(subset=['Message'], keep=False)) & (df['word_count_group'] == 'regular msg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37b5175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_msg_subset = df[df['word_count_group'] == 'regular msg'].copy()\n",
    "regular_msg_subset.drop_duplicates(subset=['Message'], keep='first', inplace=True)\n",
    "df.loc[df['word_count_group'] == 'regular msg'] = regular_msg_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c473f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Message</th>\n",
       "      <th>clean_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>2021-04-11</td>\n",
       "      <td>19:13:00</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>Muchachos, debo dejar el grupo por problemas p...</td>\n",
       "      <td>muchachos debo dejar el grupo por problemas pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8010</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>21:26:00</td>\n",
       "      <td>Loro</td>\n",
       "      <td>Los nuevos rufianes kirchneristas: DANIEL VILA...</td>\n",
       "      <td>los nuevos rufianes kirchneristas daniel vila ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11127</th>\n",
       "      <td>2021-08-24</td>\n",
       "      <td>21:51:00</td>\n",
       "      <td>Juan</td>\n",
       "      <td>Totalmente negro. Sabias palabras. Una forma d...</td>\n",
       "      <td>totalmente negro sabias palabras una forma de ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      Time  Sender  \\\n",
       "3114   2021-04-11  19:13:00  Garcia   \n",
       "8010   2021-06-29  21:26:00    Loro   \n",
       "11127  2021-08-24  21:51:00    Juan   \n",
       "\n",
       "                                                 Message  \\\n",
       "3114   Muchachos, debo dejar el grupo por problemas p...   \n",
       "8010   Los nuevos rufianes kirchneristas: DANIEL VILA...   \n",
       "11127  Totalmente negro. Sabias palabras. Una forma d...   \n",
       "\n",
       "                                               clean_msg  \n",
       "3114   muchachos debo dejar el grupo por problemas pe...  \n",
       "8010   los nuevos rufianes kirchneristas daniel vila ...  \n",
       "11127  totalmente negro sabias palabras una forma de ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_msg_condition = (df['word_count_group'] == 'regular msg') & df['Message'].str.contains(\n",
    "    'Los nuevos rufianes kirchneristas: DANIEL VILA...|'\n",
    "    'Totalmente negro. Sabias palabras. Una forma d...|'\n",
    "    'Muchachos, debo dejar el grupo por problemas p...',\n",
    "    case=False\n",
    ")\n",
    "\n",
    "df[['Date', 'Time', 'Sender', 'Message', 'clean_msg']][regular_msg_condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa31788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bbf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ac16145",
   "metadata": {},
   "source": [
    "# 3. Feature engineering\n",
    "At this stage we prepare the data for exploration:\n",
    "* we are going to separate the emojis from the messages in order to analyse the polarity of each one.\n",
    "* We are going to separate the date from the time in order to take advantage of both variables.\n",
    "* finally, we will analyse the polarity of the messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a8df1",
   "metadata": {},
   "source": [
    "## Message engineering | Spliting emojis from messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67aa8173",
   "metadata": {},
   "outputs": [],
   "source": [
    "Emoticon_to_replace = [\n",
    "    (r'^\\?\\s*$', '‚ùì'),          # Replace ? with emoji\n",
    "    (r'^\\!\\s*$', '‚ùó'),          # Replace ! with emoji\n",
    "    (r'^:\\-\\)$', 'üòÇ'),          # Replace :-) with emoji\n",
    "    (r'^;\\-\\)$', 'üòâ'),          # Replace ;-) with emoji\n",
    "\n",
    "    (r'\\b(ojo+)+\\b', '‚ö†Ô∏è'),      # Replace comment with emoji\n",
    "    (r'\\b(epa+)+\\b', '‚ö†Ô∏è'),      # Replace comment with emoji\n",
    "    (r'\\b(apa+)+\\b', '‚ö†Ô∏è'),      # Replace comment with emoji\n",
    "\n",
    "    (r'\\b(?:j[aj]*a[aj]*j[aj]*|ja(?:j[aj]*a[aj]*)*|ja(?:j[ak]*a[aj]*)*|ja+)\\b', 'üòÇ'),  # Replace jajaja with emoji\n",
    "    (r'\\b(?:j[ej]*e[ej]*j[ej]*|je(?:j[ej]*e[ej]*)*)\\b', 'üòÇ'),                          # Replace jejeje with emoji\n",
    "    (r'\\b(?:j[oj]*o[oj]*j[oj]*|jo(?:j[oj]*o[oj]*)*|jo(?:j[ok]*o[oj]*)*|jo+)\\b', 'üòÇ'),  # Replace jojojo with emoji\n",
    "    (r'\\b(?:j[uj]*u[uj]*j[uj]*|ju(?:j[uj]*u[uj]*)*|ju(?:j[uk]*u[uj]*)*|ju+)\\b', 'üòÇ'),  # Replace jujuju with emoji\n",
    "    (r'\\b(jiji|jijij)\\b', 'üòÇ'),                                                        # Replace jijiji with emoji\n",
    "]\n",
    "\n",
    "# Apply the function to the 'Message' column \n",
    "df['Message'] = df['Message'].apply(lambda x: apply_regex_patterns(x, Emoticon_to_replace)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8519692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "# Emoji extraction\n",
    "df['emoji'] = df['Message'].apply(lambda x: ''.join(c for c in str(x) if c in emoji.EMOJI_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab80b572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emoji\n",
       "          36757\n",
       "üòÇ           362\n",
       "ü§∑üèª‚ôÇ         200\n",
       "ü§¶üèª‚ôÇ         101\n",
       "ü§≠            65\n",
       "ü§î            61\n",
       "ü§™            56\n",
       "ü§∑üèª‚ôÇü§¶üèª‚ôÇ       49\n",
       "‚ö†            48\n",
       "üòâ            47\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emoji'].value_counts().iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06463f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ff48ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emoji\n",
       "        36757\n",
       "üòÇ         362\n",
       "ü§∑üèª        200\n",
       "ü§¶üèª        106\n",
       "ü§≠          65\n",
       "ü§î          61\n",
       "ü§™          56\n",
       "ü§∑üèªü§¶üèª       49\n",
       "‚ö†Ô∏è         48\n",
       "üòâ          47\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove ‚ôÇ and replace ‚ö† with ‚ö†Ô∏è from emoji column\n",
    "filtered_df = df[df['emoji'].str.contains(r'‚ôÇ', case=False, regex=True)]\n",
    "df['emoji'] = df['emoji'].str.replace(r'‚ôÇ', '', regex=True, flags=re.IGNORECASE)\n",
    "df['emoji'] = df['emoji'].str.replace(r'‚ö†', '‚ö†Ô∏è', regex=True, flags=re.IGNORECASE)\n",
    "df['emoji'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad3ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "797f30c2",
   "metadata": {},
   "source": [
    "## Message engineering | Dropping empty messages\n",
    "So far I have only replaced wrong or meaningless values by '', in this last step I filter out all the \"\" and delete the rows. Then I do the same with the null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf34569d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17457, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values on both columns (clean_msg and emoji)\n",
    "df[(df['clean_msg'] == '') & (df['emoji'] == '')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1bc5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where both 'clean_msg' and 'emoji' are empty\n",
    "mask = (df['clean_msg'] == '') & (df['emoji'] == '')\n",
    "\n",
    "# Drop the rows that meet the condition\n",
    "df_filtered = df[~mask]\n",
    "df.drop(df[mask].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68fa5d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                5\n",
       "Time                5\n",
       "Sender              5\n",
       "Message             5\n",
       "clean_msg           5\n",
       "word_count          5\n",
       "word_count_group    5\n",
       "emoji               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b0369a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null values\n",
    "df.dropna(subset=['clean_msg'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a90c9f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_msg\n",
       "                    1084\n",
       "(risa)               471\n",
       "estoy de acuerdo     207\n",
       "me sorprende         186\n",
       "me gust√≥ eso         166\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_msg'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ad586e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emoji\n",
       "        19295\n",
       "üòÇ         362\n",
       "ü§∑üèª        200\n",
       "ü§¶üèª        106\n",
       "ü§≠          65\n",
       "ü§î          61\n",
       "ü§™          56\n",
       "ü§∑üèªü§¶üèª       49\n",
       "‚ö†Ô∏è         48\n",
       "üòâ          47\n",
       "üëèüëèüëè        45\n",
       "üëèüëèüëèüëè       41\n",
       "ü§¶          39\n",
       "ü§£ü§£ü§£        32\n",
       "üò≥          32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emoji'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9427da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace remaining 1084 '' in column Clean_msg and 19295 in column Emoji\n",
    "white_space_to_replace = [(r'^\\s*$', '_')]   \n",
    "\n",
    "# Apply the function to the 'Message' column \n",
    "df['emoji'] = df['emoji'].apply(lambda x: apply_regex_patterns(x, white_space_to_replace)) \n",
    "df['clean_msg'] = df['clean_msg'].apply(lambda x: apply_regex_patterns(x, white_space_to_replace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822a4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1607c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1faa1dcc",
   "metadata": {},
   "source": [
    "## Date engineering | Date format and extraction of year, month and day of week\n",
    "At this point, I modify the date format because I need to filter messages by date, as my plan is to analyse from 01/2022 onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a17a1d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rDate</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Time</th>\n",
       "      <th>Sender</th>\n",
       "      <th>clean_msg</th>\n",
       "      <th>emoji</th>\n",
       "      <th>word_count_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>04:05:00</td>\n",
       "      <td>Eze</td>\n",
       "      <td>(risa)</td>\n",
       "      <td>ü§¶</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>04:34:00</td>\n",
       "      <td>Barde</td>\n",
       "      <td>(risa)</td>\n",
       "      <td>_</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>07:25:00</td>\n",
       "      <td>Juan</td>\n",
       "      <td>finoli finoli</td>\n",
       "      <td>_</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>07:25:00</td>\n",
       "      <td>Juan</td>\n",
       "      <td>tiene una amonestaci√≥n colectiva schames</td>\n",
       "      <td>_</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>12:41:00</td>\n",
       "      <td>Matias</td>\n",
       "      <td>me gust√≥ eso</td>\n",
       "      <td>_</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rDate  Month  Year  Weekday      Time  Sender  \\\n",
       "2  2021-02-02      2  2021  Tuesday  04:05:00     Eze   \n",
       "5  2021-02-02      2  2021  Tuesday  04:34:00   Barde   \n",
       "6  2021-02-02      2  2021  Tuesday  07:25:00    Juan   \n",
       "7  2021-02-02      2  2021  Tuesday  07:25:00    Juan   \n",
       "11 2021-02-02      2  2021  Tuesday  12:41:00  Matias   \n",
       "\n",
       "                                   clean_msg emoji word_count_group  \n",
       "2                                     (risa)     ü§¶        short msg  \n",
       "5                                     (risa)     _        short msg  \n",
       "6                              finoli finoli     _        short msg  \n",
       "7   tiene una amonestaci√≥n colectiva schames     _        short msg  \n",
       "11                              me gust√≥ eso     _        short msg  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new column 'rDate' with the datetime values\n",
    "df['rDate'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Extract month, year, and weekday information\n",
    "df['Month'] = df['rDate'].dt.month\n",
    "df['Year'] = df['rDate'].dt.year\n",
    "df['Weekday'] = df['rDate'].dt.day_name()\n",
    "\n",
    "# Handle missing values in 'Month'\n",
    "df['Month'] = df['Month'].fillna(-1)  # Replace NaN with -1 or any suitable value\n",
    "df['Month'] = df['Month'].astype(int)\n",
    "\n",
    "# Handle missing values in 'Year' (if needed)\n",
    "df['Year'] = df['Year'].fillna(-1)  # Replace NaN with -1 or any suitable value\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "selected_columns = ['rDate', 'Month', 'Year', 'Weekday', 'Time', 'Sender', 'clean_msg', 'emoji', 'word_count_group']\n",
    "df = df[selected_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af1dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a2816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4eebbc9",
   "metadata": {},
   "source": [
    "##  Time engineering | Split Time to get Daytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5ba59df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rDate</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Time</th>\n",
       "      <th>hour</th>\n",
       "      <th>Time-Day</th>\n",
       "      <th>Morning</th>\n",
       "      <th>Afternoon</th>\n",
       "      <th>Night</th>\n",
       "      <th>Sender</th>\n",
       "      <th>clean_msg</th>\n",
       "      <th>emoji</th>\n",
       "      <th>word_count_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>04:05:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Night</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Eze</td>\n",
       "      <td>(risa)</td>\n",
       "      <td>ü§¶</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>04:34:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Night</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Barde</td>\n",
       "      <td>(risa)</td>\n",
       "      <td>_</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>07:25:00</td>\n",
       "      <td>7</td>\n",
       "      <td>Morning</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Juan</td>\n",
       "      <td>finoli finoli</td>\n",
       "      <td>_</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>07:25:00</td>\n",
       "      <td>7</td>\n",
       "      <td>Morning</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Juan</td>\n",
       "      <td>tiene una amonestaci√≥n colectiva schames</td>\n",
       "      <td>_</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>12:41:00</td>\n",
       "      <td>12</td>\n",
       "      <td>Morning</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Matias</td>\n",
       "      <td>me gust√≥ eso</td>\n",
       "      <td>_</td>\n",
       "      <td>short msg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rDate  Month  Year  Weekday      Time  hour Time-Day  Morning  \\\n",
       "2  2021-02-02      2  2021  Tuesday  04:05:00     4    Night        0   \n",
       "5  2021-02-02      2  2021  Tuesday  04:34:00     4    Night        0   \n",
       "6  2021-02-02      2  2021  Tuesday  07:25:00     7  Morning        1   \n",
       "7  2021-02-02      2  2021  Tuesday  07:25:00     7  Morning        1   \n",
       "11 2021-02-02      2  2021  Tuesday  12:41:00    12  Morning        1   \n",
       "\n",
       "    Afternoon  Night  Sender                                 clean_msg emoji  \\\n",
       "2           0      1     Eze                                    (risa)     ü§¶   \n",
       "5           0      1   Barde                                    (risa)     _   \n",
       "6           0      0    Juan                             finoli finoli     _   \n",
       "7           0      0    Juan  tiene una amonestaci√≥n colectiva schames     _   \n",
       "11          0      0  Matias                              me gust√≥ eso     _   \n",
       "\n",
       "   word_count_group  \n",
       "2         short msg  \n",
       "5         short msg  \n",
       "6         short msg  \n",
       "7         short msg  \n",
       "11        short msg  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Time_str'] = df['Time'].astype(str)\n",
    "df['hour'] = df['Time_str'].str.extract(r'(\\d{2})').astype(int)\n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S').dt.time\n",
    "\n",
    "# Create new columns for morning, afternoon, and night\n",
    "df['Morning'] = ((df['Time'].apply(lambda x: x.hour) >= 6) & (df['Time'].apply(lambda x: x.hour) < 13)).astype(int)\n",
    "df['Afternoon'] = ((df['Time'].apply(lambda x: x.hour) >= 13) & (df['Time'].apply(lambda x: x.hour) < 20)).astype(int)\n",
    "df['Night'] = ((df['Time'].apply(lambda x: x.hour) >= 20) | (df['Time'].apply(lambda x: x.hour) < 6)).astype(int)\n",
    "\n",
    "# Combine morning, afternoon, and night into a single column 'Time-Day'\n",
    "def classify_time(row):\n",
    "    if row['Morning'] == 1:\n",
    "        return 'Morning'\n",
    "    elif row['Afternoon'] == 1:\n",
    "        return 'Afternoon'\n",
    "    elif row['Night'] == 1:\n",
    "        return 'Night'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['Time-Day'] = df.apply(classify_time, axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "selected_columns = ['rDate', 'Month', 'Year','Weekday','Time','hour','Time-Day','Morning','Afternoon','Night',\n",
    "                    'Sender','clean_msg','emoji','word_count_group']\n",
    "df = df[selected_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca6b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42c8e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b07d3206",
   "metadata": {},
   "source": [
    "## Sentiment analysis | Apply sentiment analysis to clean msg\n",
    "In this step we are going to perform the sentiment analysis on the messages, first we are going to filter the messages belonging to 2023 to focus our analysis on a recent period (we have 2019-2023).\n",
    "Then we will import the necessary libraries and we will be able to run the sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbe9425c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9770, 14)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[df['Year']== 2023]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d7aef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d700bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pretrained model\n",
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b209705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_token(text):\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.encode(text, return_tensors='pt', truncation=True)\n",
    "    \n",
    "    # Check if the tokens exceed the maximum sequence length\n",
    "    if tokens.size(1) > 512:\n",
    "        print(f\"Tokens size exceeds maximum sequence length: {tokens.size(1)}\")\n",
    "        # Pad the tensor if needed\n",
    "        tokens = F.pad(tokens, (0, 512 - tokens.size(1)))\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    blob = model(tokens)\n",
    "    \n",
    "    # Return the sentiment polarity\n",
    "    return int(torch.argmax(blob.logits)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fa88700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_token(text):\n",
    "    tokens = tokenizer.encode(text, return_tensors='pt')\n",
    "    blob = model(tokens)\n",
    "    return int(torch.argmax(blob.logits)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fd12e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.0734772999999791 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "get_sentiment_token('no me gusta eso')\n",
    "\n",
    "end_time = timeit.default_timer()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14263e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_token('me gusta eso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a8b8103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 860.3860365 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Create a copy of the DataFrame to avoid SettingWithCopyWarning\n",
    "data_copy = data.copy()\n",
    "\n",
    "# Apply sentiment analysis to each row of the 'clean_msg' column\n",
    "data_copy['Sentiment_Polarity'] = data_copy['clean_msg'].apply(lambda x: get_sentiment_token(x))\n",
    "\n",
    "# Map sentiment polarity to labels\n",
    "data_copy['Sentiment_Label'] = data_copy['Sentiment_Polarity'].map({5: 'Positive', 1: 'Negative', 3: 'Neutral'})\n",
    "\n",
    "# Save the labeled data to a CSV file\n",
    "data_copy.to_csv('data_labeled.csv', index=False)\n",
    "\n",
    "end_time = timeit.default_timer()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb5b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c243fb49",
   "metadata": {},
   "source": [
    "## Emoji | Apply emosent analysis to emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8874bbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9770, 16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "data_labeled = pd.read_csv('data_labeled.csv')\n",
    "data_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dd025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emosent import get_emoji_sentiment_rank\n",
    "\n",
    "def emosent_score(emoji):\n",
    "    score, count = 0, 0\n",
    "    for e in set(emoji):\n",
    "        try:\n",
    "            score += get_emoji_sentiment_rank(e)['sentiment_score']\n",
    "            count += 1\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Calculate the sentiment score based on your formula\n",
    "    return score / count if count != 0 else score\n",
    "\n",
    "# Apply sentiment analysis to each row of the 'emoji' column\n",
    "data_labeled['Emosent_Polarity'] = data_labeled['emoji'].apply(lambda x: emosent_score(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map sentiment polarity to labels\n",
    "def map_emotion_label(polarity):\n",
    "    if polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply the function to create the 'Emosent_Label' column\n",
    "data_labeled['Emosent_Label'] = data_labeled['Emosent_Polarity'].apply(map_emotion_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6af82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labeled['is_msg'] = data_labeled['clean_msg'].apply(lambda x: '-' if pd.isna(x) or x == '' else 'msg')\n",
    "data_labeled['clean_msg'].fillna('-', inplace=True)\n",
    "\n",
    "data_labeled['is_emoji'] = data_labeled['emoji'].apply(lambda x: '-' if pd.isna(x) or x == '' else 'emoji')\n",
    "data_labeled['emoji'].fillna('-', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280d375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb5afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d455ecb",
   "metadata": {},
   "source": [
    "# 4. Let's start with Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d515f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2012e8",
   "metadata": {},
   "source": [
    "## Most common words | Word-cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5088584",
   "metadata": {},
   "source": [
    "### Word-cloud | Remove Stop-words \n",
    "At this point I make sure, the words have the correct sensitive polarity and I clean the stop words so that the most used words can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbcd7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove stop-words\n",
    "data_filtered = data_labeled\n",
    "stopwords_list = pd.read_csv('stopwords.csv', encoding='ISO-8859-1')['words'].tolist()\n",
    "data_filtered['clean_words'] = data_filtered['clean_msg'].apply(lambda x: ' '.join([word for word in str(x).split() if word.lower() not in stopwords_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd1b21",
   "metadata": {},
   "source": [
    "### Word-cloud | Remove remaining Stop-words manually\n",
    "Some words not included in the stop-words file are still in the list of positive words. I remove them to leave only nouns, adjectives and other words that really represent the positive meaning of the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(o)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(ayer)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(mucha)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(muchas)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(mucho)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(ahi)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(esos)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(otro)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(hoy)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(nada)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(nada)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(est√°)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(est√°s)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(ahora)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(esto)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(tanto)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(cumpleee)+\\b', 'cumple', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(c√≥mo)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(ver)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(x)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(dice)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(creo)+\\b', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b629ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color = 'white',\n",
    "        max_words = 200,\n",
    "        max_font_size = 40, \n",
    "        scale = 3,\n",
    "        random_state = 42\n",
    "    ).generate(str(data))\n",
    "    #).generate(data)\n",
    "\n",
    "    fig = plt.figure(1, figsize = (20, 20))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize = 20)\n",
    "        fig.subplots_adjust(top = 2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8008c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive = data_filtered[data_filtered[\"Sentiment_Label\"] == 'Positive']\n",
    "concatenated_message = ''\n",
    "for i in range(Positive.shape[0]):\n",
    "    concatenated_message += ' ' + Positive['clean_words'].iloc[i]\n",
    "\n",
    "# to remove leading space\n",
    "concatenated_message = concatenated_message.strip()\n",
    "show_wordcloud(concatenated_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d00a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2251c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Negative = data_filtered[data_filtered[\"Sentiment_Label\"] == 'Negative']\n",
    "Negative_concatenated = ''\n",
    "for i in range(Negative.shape[0]):\n",
    "    Negative_concatenated += ' ' + Negative['clean_words'].iloc[i]\n",
    "\n",
    "# to remove leading space\n",
    "Negative_concatenated = Negative_concatenated.strip()\n",
    "show_wordcloud(Negative_concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65177807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a240554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87aab7ec",
   "metadata": {},
   "source": [
    "## Conversation stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9df1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['rDate', 'Month', 'Year', 'Weekday', 'Time', 'Time-Day', 'Morning',\n",
    "       'Afternoon', 'Night', 'Sender', 'clean_msg', 'emoji','word_count_group',\n",
    "       'Sentiment_Label', 'Emosent_Label', 'is_msg', 'is_emoji','clean_words']\n",
    "\n",
    "chat = data_labeled[selected_columns]\n",
    "\n",
    "# Assuming 'Time' is the current name of the column and data_filtered is your DataFrame\n",
    "chat = chat.rename(columns={'rDate': 'date'})\n",
    "chat = chat.rename(columns={'Time': 'hour'})\n",
    "chat = chat.rename(columns={'Sentiment_Label': 'sentiment'})\n",
    "chat = chat.rename(columns={'Sender': 'username'})\n",
    "chat = chat.rename(columns={'clean_msg': 'message'})\n",
    "chat = chat.rename(columns={'Emosent_Label': 'emosent'})\n",
    "chat = chat.rename(columns={'word_count_group': 'msg_categ'})\n",
    "\n",
    "chat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83127067",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d165f2",
   "metadata": {},
   "source": [
    "## Use of emojis\n",
    "The results showed that üòÇ Face with Tears of Joy was the most commonly used emoji, followed by üëç Thumbs Up, üôè Folded Hands, and ü•∞ Smiling Face with Hearts. According to Emojipedia, these emojis suggest positive emotions, which could be assumed that the chat messages with emojis tended to be more positive in tone.\n",
    "\n",
    "Next, I analyzed the word count of the messages sent by each member to understand their communication styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32021dd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chat.groupby('username').agg({'message': 'count',\n",
    "                              'emoji': lambda x: ' '.join(set(emoji for emojis in x.dropna() for emoji in emojis))\n",
    "                              }).sort_values(by='message', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbce163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe801f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "emoji_counter = Counter()\n",
    "\n",
    "# Iterate over each message in the 'emoji' column\n",
    "for message in chat['emoji']:\n",
    "    # Check if the message is not NaN and is a string\n",
    "    if not pd.isna(message) and isinstance(message, str):\n",
    "        # Exclude \"_\" emoji and update the counter\n",
    "        emoji_counter.update(emoji for emoji in message if emoji != \"_\")\n",
    "\n",
    "# Create a DataFrame from the Counter\n",
    "emoji_df = pd.DataFrame(emoji_counter.most_common(), columns=['emoji', 'count'], index=range(1, len(emoji_counter) + 1))\n",
    "\n",
    "chat['emoji'] = chat['emoji'].replace({'üèª':'ü§∑'})\n",
    "chat['emoji'] = chat['emoji'].replace({'‚ö†':'‚ö†Ô∏è'})\n",
    "\n",
    "# Display the top 20 emojis\n",
    "emoji_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a30e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat['is_emoji_empty'] = chat['emoji'].apply(lambda x: 0 if pd.isna(x) or x == '_' else 1)\n",
    "grouped_chat = chat.groupby('is_emoji_empty').size().reset_index(name='count')\n",
    "\n",
    "chat['is_emoji'] = chat['emoji'].apply(lambda x: True if x != '_' else False)\n",
    "grouped_chat = chat.groupby('is_emoji').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c84651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a pie chart using Plotly\n",
    "fig = go.Figure(data=go.Pie(\n",
    "    labels=['Chats without emoji', 'Chats with emoji'],\n",
    "    values=grouped_chat['count'],\n",
    "    hole=0.4,marker=dict(colors=['#25D366', '#075E54']),\n",
    "    title=dict(text='<b>Overall</b>', font=dict(size=16))))\n",
    "\n",
    "fig.update_traces(hoverinfo='label+value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Pie(labels=['Negative', 'Neutral', 'Positive'],\n",
    "                            values=chat.groupby('sentiment').count()[['message']].reset_index()['message'],\n",
    "                             hole=.4, marker=dict(colors=['#075E54', '#dcf8c6', '#25D366']),\n",
    "                             title=dict(text='<b>Overall</b>', font=dict(size=16))))\n",
    "\n",
    "fig.update_traces(hoverinfo='label+value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a01103",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd182e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "\n",
    "fig.add_trace(go.Pie(labels=['Negative', 'Neutral', 'Positive'],\n",
    "                     values=chat[chat.msg_categ == 'short msg'].groupby('sentiment').count()[['message']].reset_index()['message'],\n",
    "                     marker=dict(colors=['#075E54','#dcf8c6', '#25D366', ]),\n",
    "                     title=dict(text='<b>short msg</b>', font=dict(size=16))), 1, 1)\n",
    "\n",
    "fig.add_trace(go.Pie(labels=['Negative', 'Neutral', 'Positive'],\n",
    "                     values=chat[chat.msg_categ == 'regular msg'].groupby('sentiment').count()[['message']].reset_index()['message'],\n",
    "                     hole=.4, marker=dict(colors=['#075E54','#dcf8c6', '#25D366', ]),\n",
    "                     title=dict(text='<b>regular msg</b>', font=dict(size=16))), 1, 2)\n",
    "\n",
    "fig.update_traces(hole=.4, hoverinfo='label+value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa58a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "\n",
    "fig.add_trace(go.Pie(labels=['Negative', 'Neutral', 'Positive'],\n",
    "                     values=chat[chat.is_emoji_empty == 0].groupby('sentiment').count()[['message']].reset_index()['message'],\n",
    "                     marker=dict(colors=['#075E54','#dcf8c6', '#25D366', ]),\n",
    "                     title=dict(text='<b>without Emoji</b>', font=dict(size=16))), 1, 1)\n",
    "\n",
    "fig.add_trace(go.Pie(labels=['Negative', 'Neutral', 'Positive'],\n",
    "                     values=chat[chat.is_emoji_empty == 1].groupby('sentiment').count()[['message']].reset_index()['message'],\n",
    "                     hole=.4, marker=dict(colors=['#075E54','#dcf8c6', '#25D366', ]),\n",
    "                     title=dict(text='<b>with Emoji</b>', font=dict(size=16))), 1, 2)\n",
    "\n",
    "fig.update_traces(hole=.4, hoverinfo='label+value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96aa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b6e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c4611f7",
   "metadata": {},
   "source": [
    "## Message length\n",
    "Next, I analyzed the word count of the messages sent by each member to understand their communication styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e48217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whatstk import WhatsAppChat, FigureBuilder\n",
    "\n",
    "fig = FigureBuilder(chat.assign(message=chat['message'].apply(lambda x: ''.join([' ' for i in range(len(x.split())) if x != '<Media omitted>'])))\n",
    "                    ).user_msg_length_boxplot(title='User message length', xlabel=None)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d085e60f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25dc4ad2",
   "metadata": {},
   "source": [
    "## Message activity\n",
    "Looking at the conversation stats, it was pretty obvious that some members were more active than others. But, to really get what was going on in this group chat, I needed to see how often messages were being sent over time. Thus, I delved deeper to get the scoop on message activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e44bf",
   "metadata": {},
   "source": [
    "## Activity by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b974d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat['date'] = pd.to_datetime(chat['date'])\n",
    "# chat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c87f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureBuilder(chat).user_interventions_count_linechart(title=None, xlabel=None, all_users=True)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c74c4",
   "metadata": {},
   "source": [
    "## Members interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a15d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureBuilder(chat).user_interventions_count_linechart(date_mode='date', title=None, xlabel=None)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce942601",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureBuilder(chat).user_interventions_count_linechart(cumulative=True, title=None, xlabel=None)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ef5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be89ae3d",
   "metadata": {},
   "source": [
    "## Activity by hour "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3379db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat['hour'] = pd.to_datetime(chat['hour']).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ebae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(chat, index='hour', columns='Time-Day', values='message', aggfunc='count').fillna(0)\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9308fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='hour', data=chat, palette='viridis')\n",
    "plt.title('Distribution of messages')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Messages')\n",
    "plt.legend(title='', title_fontsize='12')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34072dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='hour', hue='Time-Day', data=chat, palette='viridis')\n",
    "plt.title('Distribution of messages')\n",
    "plt.xlabel('Time-Day')\n",
    "plt.ylabel('Quantity')\n",
    "plt.legend(title='Hour', title_fontsize='12')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520acbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341534a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc9f942",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(chat, index='hour', columns='Weekday', values='message', aggfunc='count').fillna(0)\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(chat, index='hour', columns='Weekday', values='message', aggfunc='count').fillna(0)\n",
    "heatmap = go.Heatmap(z=pivot.values,\n",
    "                     x=pivot.columns,\n",
    "                     y=pivot.index,\n",
    "                     hovertemplate='Interventions at %{y}-hour<extra>%{z}</extra>',\n",
    "                     colorscale='Greens')\n",
    "fig = go.Figure(data=[heatmap]).update_layout(xaxis={'categoryorder': 'array',\n",
    "                                                     'categoryarray': ['Monday', 'Tuesday', 'Wednesday',\n",
    "                                                                       'Thursday', 'Friday', 'Saturday', 'Sunday']})\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46842b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(chat, index='Time-Day', columns='Weekday', values='message', aggfunc='count').fillna(0)\n",
    "heatmap = go.Heatmap(z=pivot.values,\n",
    "                     x=pivot.columns,\n",
    "                     y=pivot.index,\n",
    "                     hovertemplate='Interventions at %{y}-Time-Day<extra>%{z}</extra>',\n",
    "                     colorscale='Greens')\n",
    "fig = go.Figure(data=[heatmap]).update_layout(xaxis={'categoryorder': 'array',\n",
    "                                                     'categoryarray': ['Monday', 'Tuesday', 'Wednesday',\n",
    "                                                                       'Thursday', 'Friday', 'Saturday', 'Sunday']})\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat['date'] = pd.to_datetime(chat['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_chat = chat.groupby('hour').size().reset_index(name='count')\n",
    "hour_chat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureBuilder(chat).user_interventions_count_linechart(\n",
    "    date_mode='weekday',\n",
    "    title=None,\n",
    "    xlabel=None).update_layout(xaxis={'tickvals': [0, 1, 2, 3, 4, 5, 6],\n",
    "    'ticktext': ['Monday', 'Tuesday', 'Wednesday','Thursday', 'Friday', 'Saturday', 'Sunday']})\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae31a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd88cd68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca7ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17d6ad05",
   "metadata": {},
   "source": [
    "## Member interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureBuilder(chat).user_message_responses_heatmap(title=None)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36c540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb69ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureBuilder(chat).user_message_responses_flow(title=None)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54169dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065c74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71932715",
   "metadata": {},
   "source": [
    "## How everyone‚Äôs feeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56903c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# + and - by user\n",
    "pivot = pd.pivot_table(chat, index='sentiment',\n",
    "                       columns='username',\n",
    "                       values='message',\n",
    "                       aggfunc='count').apply(lambda x: x/x.sum(), axis=0)\n",
    "heatmap = go.Heatmap(z=pivot.values,\n",
    "                     x=pivot.columns,\n",
    "                     y=pivot.index,\n",
    "                     hovertemplate='Interventions<extra>%{z:.2%}</extra>',\n",
    "                     colorscale='Greens')\n",
    "fig = go.Figure(data=[heatmap])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2954cc",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "After analyzing our WhatsApp group chat, it can be concluded that our group chat was a \n",
    "fun and supportive space where everyone showed appreciation for one another and had a good laugh. \n",
    "Despite a mostly neutral sentiment, the use of emojis added a positive touch. The chat‚Äôs topics vary greatly, from casual banter to serious discussions, making for an engaging and diverse conversation.\n",
    "Overall, the analysis provided valuable insights into what our group chat is all about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1bc9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575ff64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bea191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4afe26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
