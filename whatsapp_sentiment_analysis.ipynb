{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8863a50",
   "metadata": {},
   "source": [
    "# Whatsapp group sentiment analysis\n",
    "In this work I make a model to know the polarity of the sentiments of the messages in a whatsapp group.\n",
    "\n",
    "In the development of the work I will analyse different aspects of the dynamics of the group, highlighting the activity of the different users, the type of messages and the topics that were discussed with their corresponding polarity.\n",
    "\n",
    "this is my final work of the data analytic bootcamp, and i decided to do this work because i believe that the spontaneity and quantity of the messages are an extremely valuable resource to know the opinion of the people about relevant topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea776ef",
   "metadata": {},
   "source": [
    "# 1. Import basic libraries & read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import timedelta\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199167c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your text file\n",
    "file_path = 'WhatsApp.txt'\n",
    "\n",
    "# Initialize lists to store parsed information\n",
    "dates = []\n",
    "times = []\n",
    "senders = []\n",
    "messages = []\n",
    "\n",
    "# Define a regular expression pattern to extract information\n",
    "pattern = re.compile(r'(\\d+/\\d+/\\d+ \\d+:\\d+) - ([^:]+): (.+)')\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    # Iterate through each line in the file\n",
    "    for line in file:\n",
    "        # Use the regular expression to match and extract information\n",
    "        match = pattern.match(line.strip())\n",
    "        if match:\n",
    "            # Extract date, time, sender, and message\n",
    "            datetime_str, sender, message = match.groups()\n",
    "\n",
    "            # Convert date and time to a datetime object\n",
    "            datetime_obj = datetime.strptime(datetime_str, '%d/%m/%y %H:%M')\n",
    "\n",
    "            # Append information to the respective lists\n",
    "            dates.append(datetime_obj.date())\n",
    "            times.append(datetime_obj.time())\n",
    "            senders.append(sender)\n",
    "            messages.append(message)\n",
    "\n",
    "# Create a DataFrame for easier analysis\n",
    "df = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Time': times,\n",
    "    'Sender': senders,\n",
    "    'Message': messages\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a76592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the nickname mapping from CSV into a DataFrame\n",
    "nickname_mapping = pd.read_csv('sender_nickname.csv')\n",
    "\n",
    "# Create a mapping dictionary from 'Full Name' to 'Nickname'\n",
    "name_mapping_dict = dict(zip(nickname_mapping['Full Name'], nickname_mapping['Nickname']))\n",
    "\n",
    "# Replace values in the 'Sender' column of the original DataFrame (df) using the mapping\n",
    "df['Sender'] = df['Sender'].replace(name_mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058b21a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c6668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bcd936e",
   "metadata": {},
   "source": [
    "#  2.Data Preparation and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e9e9b",
   "metadata": {},
   "source": [
    "## Understanding the data\n",
    "Before we start cleaning the dataset, we need to understand the business and the data structure\n",
    "* we can see that the dataset has 3 columns (date, sender and message)\n",
    "* we have 39972 messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7191e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a23324e",
   "metadata": {},
   "source": [
    "## Cleaning messages \n",
    "This step is critical in the sentiment analysis process - we need to make sure that the words and messages make sense to the model. It is about ensuring that the messages reach the sentiment analysis with meaning and do not cause confusion.\n",
    "To achieve this, we need to clean the messages of jargon, including all kinds of onomatopoeias, emogis and multimedia so common in whatsapp communication. \n",
    "Stop words will be cleaned up later. They are not applicable at the moment because Bert Multilanguage needs them to interpret the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column to categorize MessageCount\n",
    "msg_counts = df['Message'].value_counts().reset_index()\n",
    "msg_counts.columns = ['Message','repetition']\n",
    "msg_counts['repetition_cat'] = pd.cut(msg_counts['repetition'], bins=[0, 1, 2, 3, float('inf')],\n",
    "                                       labels=['1 msg', '2 msg', '3 msg', '>3 msg'])\n",
    "\n",
    "# Function to count words in a given text\n",
    "def count_words(text):\n",
    "    \"\"\"\n",
    "    Count the number of words in a given text.\n",
    "    Parameters:\n",
    "        text (str): The input text.\n",
    "    Returns:\n",
    "        int: The number of words in the text.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return len(text.split())\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to the 'text' column and create a new 'word_count' column\n",
    "msg_counts['word_count'] = msg_counts['Message'].apply(lambda x: count_words(x))\n",
    "\n",
    "msg_counts['word_count_cat'] = pd.cut(\n",
    "    msg_counts['word_count'],\n",
    "    bins=[0, 5, 10, float('inf')],\n",
    "    labels=['1-4 words', '5-10 words', '>10 words']\n",
    ")\n",
    "\n",
    "msg_counts['word_count_group'] = pd.cut(\n",
    "    msg_counts['word_count'],\n",
    "    bins=[0, 10, float('inf')],\n",
    "    labels=['short msg', 'regular msg']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e028ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table with totals\n",
    "result_pivot = pd.pivot_table(\n",
    "    msg_counts,\n",
    "    values='repetition',\n",
    "    index='repetition_cat',\n",
    "    columns=['word_count_group'],\n",
    "    aggfunc='sum',\n",
    "    fill_value=0,\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "\n",
    "result_pivot_filtered = result_pivot.loc[:, (result_pivot != 0).any(axis=0)]\n",
    "\n",
    "# Display the filtered result_pivot\n",
    "result_pivot_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4426fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table with totals\n",
    "result_pivot = pd.pivot_table(\n",
    "    msg_counts,\n",
    "    values='repetition',\n",
    "    index='repetition_cat',\n",
    "    columns=['word_count_cat'],\n",
    "    aggfunc='sum',\n",
    "    fill_value=0,\n",
    "    margins=True,\n",
    "    margins_name='Total'\n",
    ")\n",
    "\n",
    "result_pivot_filtered = result_pivot.loc[:, (result_pivot != 0).any(axis=0)]\n",
    "\n",
    "# Display the filtered result_pivot\n",
    "result_pivot_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cfaee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c37d3c2",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Short messages of 1 to 4 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff17e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_counts[\n",
    "    (msg_counts['word_count_cat']=='1-4 words') & \n",
    "    (msg_counts['repetition_cat'] !='1 msg')\n",
    "].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecad4eb",
   "metadata": {},
   "source": [
    "Short messages have particular characteristics, they appear very often because they are brief and it is important to understand their nature given that most of them are short answers that have no meaning of their own, they are also used to make comments with double meaning (ironies) and also the use of signs or forms that are not understandable by the model.\n",
    "* multimedia messages notes\n",
    "* deleted messages notes\n",
    "* slang or jargon\n",
    "* use of marks and letters (alphabetic characters) to write onomatopoeias (Jajajaja, Jajaj, etc...)\n",
    "* words with double meanings.\n",
    "* emogis on the other hand has to be analysed separately\n",
    "* null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9dc6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c030beb",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Replace notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04012710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_msg_to_replace(text, elements_to_replace):\n",
    "    if isinstance(text, str):\n",
    "        for element in elements_to_replace:\n",
    "            text = text.replace(element, '')\n",
    "        return text.strip().lower()\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "message_to_replace = [\n",
    "    ('<Multimedia omitido>'),\n",
    "    ('Se eliminÃ³ este mensaje.'),\n",
    "    ('ubicaciÃ³n en tiempo real compartida'),\n",
    "    ('Eliminaste este mensaje.'),\n",
    "    ('null'),\n",
    "    ('\\n'),\n",
    "]\n",
    "\n",
    "# Apply the clean_words_to_replace function to the 'Message' column\n",
    "df['clean_msg'] = df['Message'].apply(lambda x: clean_msg_to_replace(x, message_to_replace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_msg'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bfa08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1f74d91",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Replace emoticons and onomatopoeias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f9d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_regex_patterns(text, regex_patterns):\n",
    "    if isinstance(text, str):\n",
    "        for pattern, replacement in regex_patterns:\n",
    "            text = re.sub(pattern, replacement, text)\n",
    "        return text\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "# List of regex patterns and replacements\n",
    "words_to_replace = [\n",
    "    (r'[^\\w\\s]|_', ''),          # Replace everything that is not an alphabetical string, including emojis\n",
    "    (r'http\\S+', ''),            # Remove URLs\n",
    "    (r'[0-9]+',''),               # Remove numbers\n",
    "    (r'\\s+', ' '),               # Replace multiple whitespaces with a single space\n",
    "    (r'^\\d+$',''),               # Replace strings consisting entirely of digits\n",
    "    (r'([a-zA-Z])\\1\\1', '\\\\1'),  # Replace consecutive identical characters with a single character\n",
    "]\n",
    "\n",
    "# List of regex patterns and replacements\n",
    "other_words_to_replace = [\n",
    "    (r'\\!{2,}', '!'),            # Replace repetition of !!! with !\n",
    "    (r'\\!', ''),                 # Remove !\n",
    "    (r'\\?{2,}', '?'),            # Replace repetition of ??? with ?\n",
    "    (r'\\.{2,}', ''),             # Remove repetition of ...\n",
    "    (r'^\\?\\s*$', ''),            # Remove ? to treate it as emoji\n",
    "    (r'^\\!\\s*$', ''),            # Remove ! to treate it as emoji\n",
    "    (r'^:\\-\\)$', ''),            # Remove :-) to treate it as emoji\n",
    "    (r'^;\\-\\)$', ''),            # Remove ;-) to treate it as emoji\n",
    "    (r'\\b(?:j[aj]*a[aj]*j[aj]*|ja(?:j[aj]*a[aj]*)*|ja(?:j[ak]*a[aj]*)*|ja+)\\b', ''),  # Remove repetition of ja = :)\n",
    "    (r'\\b(?:j[ej]*e[ej]*j[ej]*|je(?:j[ej]*e[ej]*)*)\\b', ''),                          # Remove repetition of je = :)\n",
    "    (r'\\b(?:j[oj]*o[oj]*j[oj]*|jo(?:j[oj]*o[oj]*)*|jo(?:j[ok]*o[oj]*)*|jo+)\\b', ''),  # Remove repetition of jo = :)\n",
    "    (r'\\b(?:j[uj]*u[uj]*j[uj]*|ju(?:j[uj]*u[uj]*)*|ju(?:j[uk]*u[uj]*)*|ju+)\\b', ''),  # Remove repetition of ju = :)\n",
    "    (r'\\b(jiji|jijij)\\b', ''),                                                        # Remove repetition of ji = :) \n",
    "]\n",
    "\n",
    "# Apply the function to the 'clean_msg' column\n",
    "df['clean_msg'] = df['clean_msg'].apply(lambda x: apply_regex_patterns(x, words_to_replace))\n",
    "df['clean_msg'] = df['clean_msg'].apply(lambda x: apply_regex_patterns(x, other_words_to_replace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_msg'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229a44af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38d390da",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Replace short messages with doble meaning\n",
    "At this point I reemploy the short messages with double meanings by a phrase that replaces the real meaning of the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170e3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_patterns(series, patterns):\n",
    "    for pattern, replacement in patterns:\n",
    "        series = series.str.replace(pattern, replacement, regex=True, flags=re.IGNORECASE)\n",
    "    return series\n",
    "\n",
    "word_replacements = pd.read_csv('word_replacements.csv')\n",
    "word_replacements_list = list(zip(word_replacements['Pattern'], word_replacements['Replacement']))\n",
    "\n",
    "cleaned_replacements_list = [\n",
    "    (rf'^\\s*{str(pattern).replace(\"nan\", \"\")}\\s*$', rf'{str(replacement).replace(\"nan\", \"\")}')\n",
    "    for pattern, replacement in word_replacements_list\n",
    "]\n",
    "\n",
    "df['clean_msg'] = apply_patterns(df['clean_msg'], cleaned_replacements_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_msg'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ae5fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79ad9265",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Replace other words and marks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2867848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_replacements(df, patterns):\n",
    "    for pattern, replacement in patterns:\n",
    "        df['clean_msg'] = df['clean_msg'].str.replace(pattern, replacement, regex=True, flags=re.IGNORECASE)\n",
    "\n",
    "# Define your replacement patterns\n",
    "replacement_patterns = [\n",
    "    (r'^Bata\\s+\\w+$', '(risa)'),\n",
    "    (r'^Basta\\s+\\w+$', '(risa)'),\n",
    "    (r'^y( si)+$', 'confirmo que si'),\n",
    "    (r'\\b(gracias)+\\b', 'gracias'),\n",
    "    (r'\\bgracias+\\b', 'gracias'),\n",
    "    (r'^Ok\\.?\\s*$', 'estoy de acuerdo'),\n",
    "    (r'^se+\\s*$', 'estoy de acuerdo'),\n",
    "    (r'^Nah+\\s*$', 'me sorprende'),\n",
    "    (r'^No+\\s*$', 'me sorprende'),\n",
    "    (r'^\\s*a+migos\\s*$', 'amigos'),\n",
    "    (r'^\\s*([a-zA-Z])\\s*$', ''),\n",
    "    (r'^@\\d+$', ''),\n",
    "    (r'^\\s+$', ''),\n",
    "    (r'^\\s*', ''),\n",
    "    (r'^\\s*si\\b(?: si)+\\s*$', 'confirmo que si'),\n",
    "    (r'^(no\\s)+no$', 'confirmo que no'),\n",
    "    (r'b*chiques\\b', 'amigos'),\n",
    "    (r'b*o estoy crazy macaya\\b', ''),\n",
    "    (r'b*no es joda\\b', 'hablo enserio'),\n",
    "    (r'\\b(Perdon)+\\b', 'perdÃ³n'),\n",
    "    (r'\\b(cumple+)+\\b', 'cumpleaÃ±os'),    \n",
    "    (r'\\b(ojo+)+\\b', ''),\n",
    "    (r'\\b(epa+)+\\b', ''),\n",
    "    (r'\\b(apa+)+\\b', ''),\n",
    "]    \n",
    "\n",
    "# Apply replacements using the function\n",
    "apply_replacements(df, replacement_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e135fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_msg'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df408f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1c099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4dfa802",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Short messages of 5 to 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c241dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_counts[\n",
    "    (msg_counts['word_count_cat']=='5-10 words') & \n",
    "    (msg_counts['repetition_cat'] !='1 msg')\n",
    "].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e730f60f",
   "metadata": {},
   "source": [
    "In this category of short messages (5-7 words) have a clear meaning and do not need modification, the repetitions are due to the fact that they are common ways of communicating. The use of multiple exclamation marks for emphasis is also observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a336be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac8e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75d37667",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Messages longer than 10 words\n",
    "As we could see in the pivot table at the beginning, there are messages of normal size that are duplicated. We can then confirm that these are duplicate messages, other than short messages...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_counts[\n",
    "    (msg_counts['word_count_cat']=='>10 words') & \n",
    "    (msg_counts['repetition_cat'] =='2 msg')\n",
    "].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d8207",
   "metadata": {},
   "source": [
    "These are normal sized messages, so there is no reason why the messages would be duplicates.\n",
    "This will most likely happen when messages are forwarded. This duplicate should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3779b20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72ff9b9c",
   "metadata": {},
   "source": [
    "## Cleaning Messages | Drop regular messages duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['Message'].apply(lambda x: count_words(x))\n",
    "\n",
    "# Creating word_count_group column based on word_count\n",
    "df['word_count_group'] = pd.cut(\n",
    "    df['word_count'],\n",
    "    bins=[0, 7, float('inf')],\n",
    "    labels=['short msg', 'regular msg']\n",
    ")\n",
    "\n",
    "df[(df.duplicated(subset=['Message'], keep=False)) & (df['word_count_group'] == 'regular msg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_msg_subset = df[df['word_count_group'] == 'regular msg'].copy()\n",
    "regular_msg_subset.drop_duplicates(subset=['Message'], keep='first', inplace=True)\n",
    "df.loc[df['word_count_group'] == 'regular msg'] = regular_msg_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c473f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_msg_condition = (df['word_count_group'] == 'regular msg') & df['Message'].str.contains(\n",
    "    'Los nuevos rufianes kirchneristas: DANIEL VILA...|'\n",
    "    'Totalmente negro. Sabias palabras. Una forma d...|'\n",
    "    'Muchachos, debo dejar el grupo por problemas p...',\n",
    "    case=False\n",
    ")\n",
    "\n",
    "df[['Date', 'Time', 'Sender', 'Message', 'clean_msg']][regular_msg_condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa31788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bbf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ac16145",
   "metadata": {},
   "source": [
    "# 3. Feature engineering\n",
    "At this stage we prepare the data for exploration:\n",
    "* we are going to separate the emojis from the messages in order to analyse the polarity of each one.\n",
    "* We are going to separate the date from the time in order to take advantage of both variables.\n",
    "* finally, we will analyse the polarity of the messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a8df1",
   "metadata": {},
   "source": [
    "## Message engineering | Spliting emojis from messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa8173",
   "metadata": {},
   "outputs": [],
   "source": [
    "Emoticon_to_replace = [\n",
    "    (r'^\\?\\s*$', 'â“'),          # Replace ? with emoji\n",
    "    (r'^\\!\\s*$', 'â—'),          # Replace ! with emoji\n",
    "    (r'^:\\-\\)$', 'ðŸ˜‚'),          # Replace :-) with emoji\n",
    "    (r'^;\\-\\)$', 'ðŸ˜‰'),          # Replace ;-) with emoji\n",
    "\n",
    "    (r'\\b(ojo+)+\\b', 'âš ï¸'),      # Replace comment with emoji\n",
    "    (r'\\b(epa+)+\\b', 'âš ï¸'),      # Replace comment with emoji\n",
    "    (r'\\b(apa+)+\\b', 'âš ï¸'),      # Replace comment with emoji\n",
    "\n",
    "    (r'\\b(?:j[aj]*a[aj]*j[aj]*|ja(?:j[aj]*a[aj]*)*|ja(?:j[ak]*a[aj]*)*|ja+)\\b', 'ðŸ˜‚'),  # Replace jajaja with emoji\n",
    "    (r'\\b(?:j[ej]*e[ej]*j[ej]*|je(?:j[ej]*e[ej]*)*)\\b', 'ðŸ˜‚'),                          # Replace jejeje with emoji\n",
    "    (r'\\b(?:j[oj]*o[oj]*j[oj]*|jo(?:j[oj]*o[oj]*)*|jo(?:j[ok]*o[oj]*)*|jo+)\\b', 'ðŸ˜‚'),  # Replace jojojo with emoji\n",
    "    (r'\\b(?:j[uj]*u[uj]*j[uj]*|ju(?:j[uj]*u[uj]*)*|ju(?:j[uk]*u[uj]*)*|ju+)\\b', 'ðŸ˜‚'),  # Replace jujuju with emoji\n",
    "    (r'\\b(jiji|jijij)\\b', 'ðŸ˜‚'),                                                        # Replace jijiji with emoji\n",
    "]\n",
    "\n",
    "# Apply the function to the 'Message' column \n",
    "df['Message'] = df['Message'].apply(lambda x: apply_regex_patterns(x, Emoticon_to_replace)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8519692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "# Emoji extraction\n",
    "df['emoji'] = df['Message'].apply(lambda x: ''.join(c for c in str(x) if c in emoji.EMOJI_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emoji'].value_counts().iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06463f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff48ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove â™‚ and replace âš  with âš ï¸ from emoji column\n",
    "filtered_df = df[df['emoji'].str.contains(r'â™‚', case=False, regex=True)]\n",
    "df['emoji'] = df['emoji'].str.replace(r'â™‚', '', regex=True, flags=re.IGNORECASE)\n",
    "df['emoji'] = df['emoji'].str.replace(r'âš ', 'âš ï¸', regex=True, flags=re.IGNORECASE)\n",
    "df['emoji'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad3ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "797f30c2",
   "metadata": {},
   "source": [
    "## Message engineering | Dropping empty messages\n",
    "So far I have only replaced wrong or meaningless values by '', in this last step I filter out all the \"\" and delete the rows. Then I do the same with the null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf34569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null values on both columns (clean_msg and emoji)\n",
    "df[(df['clean_msg'] == '') & (df['emoji'] == '')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where both 'clean_msg' and 'emoji' are empty\n",
    "mask = (df['clean_msg'] == '') & (df['emoji'] == '')\n",
    "\n",
    "# Drop the rows that meet the condition\n",
    "df_filtered = df[~mask]\n",
    "df.drop(df[mask].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0369a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null values\n",
    "df.dropna(subset=['clean_msg'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c9f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_msg'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad586e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emoji'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace remaining 1084 '' in column Clean_msg and 19295 in column Emoji\n",
    "white_space_to_replace = [(r'^\\s*$', '_')]   \n",
    "\n",
    "# Apply the function to the 'Message' column \n",
    "df['emoji'] = df['emoji'].apply(lambda x: apply_regex_patterns(x, white_space_to_replace)) \n",
    "df['clean_msg'] = df['clean_msg'].apply(lambda x: apply_regex_patterns(x, white_space_to_replace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822a4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1607c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1faa1dcc",
   "metadata": {},
   "source": [
    "## Date engineering | Date format and extraction of year, month and day of week\n",
    "At this point, I modify the date format because I need to filter messages by date, as my plan is to analyse from 01/2022 onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17a1d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'rDate' with the datetime values\n",
    "df['rDate'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Extract month, year, and weekday information\n",
    "df['Month'] = df['rDate'].dt.month\n",
    "df['Year'] = df['rDate'].dt.year\n",
    "df['Weekday'] = df['rDate'].dt.day_name()\n",
    "\n",
    "# Handle missing values in 'Month'\n",
    "df['Month'] = df['Month'].fillna(-1)  # Replace NaN with -1 or any suitable value\n",
    "df['Month'] = df['Month'].astype(int)\n",
    "\n",
    "# Handle missing values in 'Year' (if needed)\n",
    "df['Year'] = df['Year'].fillna(-1)  # Replace NaN with -1 or any suitable value\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "selected_columns = ['rDate', 'Month', 'Year', 'Weekday', 'Time', 'Sender', 'clean_msg', 'emoji', 'word_count_group']\n",
    "df = df[selected_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af1dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a2816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4eebbc9",
   "metadata": {},
   "source": [
    "##  Time engineering | Split Time to get Daytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time_str'] = df['Time'].astype(str)\n",
    "df['hour'] = df['Time_str'].str.extract(r'(\\d{2})').astype(int)\n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S').dt.time\n",
    "\n",
    "# Create new columns for morning, afternoon, and night\n",
    "df['Morning'] = ((df['Time'].apply(lambda x: x.hour) >= 6) & (df['Time'].apply(lambda x: x.hour) < 13)).astype(int)\n",
    "df['Afternoon'] = ((df['Time'].apply(lambda x: x.hour) >= 13) & (df['Time'].apply(lambda x: x.hour) < 20)).astype(int)\n",
    "df['Night'] = ((df['Time'].apply(lambda x: x.hour) >= 20) | (df['Time'].apply(lambda x: x.hour) < 6)).astype(int)\n",
    "\n",
    "# Combine morning, afternoon, and night into a single column 'Time-Day'\n",
    "def classify_time(row):\n",
    "    if row['Morning'] == 1:\n",
    "        return 'Morning'\n",
    "    elif row['Afternoon'] == 1:\n",
    "        return 'Afternoon'\n",
    "    elif row['Night'] == 1:\n",
    "        return 'Night'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['Time-Day'] = df.apply(classify_time, axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "selected_columns = ['rDate', 'Month', 'Year','Weekday','Time','hour','Time-Day','Morning','Afternoon','Night',\n",
    "                    'Sender','clean_msg','emoji','word_count_group']\n",
    "df = df[selected_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca6b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42c8e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b07d3206",
   "metadata": {},
   "source": [
    "## Sentiment analysis | Apply sentiment analysis to clean msg\n",
    "In this step we are going to perform the sentiment analysis on the messages, first we are going to filter the messages belonging to 2023 to focus our analysis on a recent period (we have 2019-2023).\n",
    "Then we will import the necessary libraries and we will be able to run the sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df['Year']== 2023]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7aef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d700bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pretrained model\n",
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b209705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_token(text):\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.encode(text, return_tensors='pt', truncation=True)\n",
    "    \n",
    "    # Check if the tokens exceed the maximum sequence length\n",
    "    if tokens.size(1) > 512:\n",
    "        print(f\"Tokens size exceeds maximum sequence length: {tokens.size(1)}\")\n",
    "        # Pad the tensor if needed\n",
    "        tokens = F.pad(tokens, (0, 512 - tokens.size(1)))\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    blob = model(tokens)\n",
    "    \n",
    "    # Return the sentiment polarity\n",
    "    return int(torch.argmax(blob.logits)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa88700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_token(text):\n",
    "    tokens = tokenizer.encode(text, return_tensors='pt')\n",
    "    blob = model(tokens)\n",
    "    return int(torch.argmax(blob.logits)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd12e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "get_sentiment_token('no me gusta eso')\n",
    "\n",
    "end_time = timeit.default_timer()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14263e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentiment_token('me gusta eso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8b8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Create a copy of the DataFrame to avoid SettingWithCopyWarning\n",
    "data_copy = data.copy()\n",
    "\n",
    "# Apply sentiment analysis to each row of the 'clean_msg' column\n",
    "data_copy['Sentiment_Polarity'] = data_copy['clean_msg'].apply(lambda x: get_sentiment_token(x))\n",
    "\n",
    "# Map sentiment polarity to labels\n",
    "data_copy['Sentiment_Label'] = data_copy['Sentiment_Polarity'].map({5: 'Positive', 1: 'Negative', 3: 'Neutral'})\n",
    "\n",
    "# Save the labeled data to a CSV file\n",
    "data_copy.to_csv('data_labeled.csv', index=False)\n",
    "\n",
    "end_time = timeit.default_timer()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb5b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c243fb49",
   "metadata": {},
   "source": [
    "## Emoji | Apply emosent analysis to emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "data_labeled = pd.read_csv('data_labeled.csv')\n",
    "data_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dd025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emosent import get_emoji_sentiment_rank\n",
    "\n",
    "def emosent_score(emoji):\n",
    "    score, count = 0, 0\n",
    "    for e in set(emoji):\n",
    "        try:\n",
    "            score += get_emoji_sentiment_rank(e)['sentiment_score']\n",
    "            count += 1\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Calculate the sentiment score based on your formula\n",
    "    return score / count if count != 0 else score\n",
    "\n",
    "# Apply sentiment analysis to each row of the 'emoji' column\n",
    "data_labeled['Emosent_Polarity'] = data_labeled['emoji'].apply(lambda x: emosent_score(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map sentiment polarity to labels\n",
    "def map_emotion_label(polarity):\n",
    "    if polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply the function to create the 'Emosent_Label' column\n",
    "data_labeled['Emosent_Label'] = data_labeled['Emosent_Polarity'].apply(map_emotion_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6af82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labeled['is_msg'] = data_labeled['clean_msg'].apply(lambda x: '-' if pd.isna(x) or x == '' else 'msg')\n",
    "data_labeled['clean_msg'].fillna('-', inplace=True)\n",
    "\n",
    "data_labeled['is_emoji'] = data_labeled['emoji'].apply(lambda x: '-' if pd.isna(x) or x == '' else 'emoji')\n",
    "data_labeled['emoji'].fillna('-', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280d375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb5afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d455ecb",
   "metadata": {},
   "source": [
    "# 4. Let's start with Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d515f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2012e8",
   "metadata": {},
   "source": [
    "## Most common words | Word-cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5088584",
   "metadata": {},
   "source": [
    "### Word-cloud | Remove Stop-words \n",
    "At this point I make sure, the words have the correct sensitive polarity and I clean the stop words so that the most used words can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbcd7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove stop-words\n",
    "data_filtered = data_labeled\n",
    "stopwords_list = pd.read_csv('stopwords.csv', encoding='ISO-8859-1')['words'].tolist()\n",
    "data_filtered['clean_words'] = data_filtered['clean_msg'].apply(lambda x: ' '.join([word for word in str(x).split() if word.lower() not in stopwords_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd1b21",
   "metadata": {},
   "source": [
    "### Word-cloud | Remove remaining Stop-words manually\n",
    "Some words not included in the stop-words file are still in the list of positive words. I remove them to leave only nouns, adjectives and other words that really represent the positive meaning of the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(o)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(ayer)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(mucha)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(muchas)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(mucho)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(ahi)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(esos)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(otro)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(hoy)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(nada)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(nada)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(estÃ¡)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(estÃ¡s)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(ahora)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(esto)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(tanto)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(cumpleee)+\\b', 'cumple', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(cÃ³mo)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(ver)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(x)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(dice)+\\b', '', regex=True)\n",
    "data_filtered['clean_msg'] = data_filtered['clean_msg'].str.replace(r'\\b(creo)+\\b', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b629ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color = 'white',\n",
    "        max_words = 200,\n",
    "        max_font_size = 40, \n",
    "        scale = 3,\n",
    "        random_state = 42\n",
    "    ).generate(str(data))\n",
    "    #).generate(data)\n",
    "\n",
    "    fig = plt.figure(1, figsize = (20, 20))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize = 20)\n",
    "        fig.subplots_adjust(top = 2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8008c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive = data_filtered[data_filtered[\"Sentiment_Label\"] == 'Positive']\n",
    "concatenated_message = ''\n",
    "for i in range(Positive.shape[0]):\n",
    "    concatenated_message += ' ' + Positive['clean_words'].iloc[i]\n",
    "\n",
    "# to remove leading space\n",
    "concatenated_message = concatenated_message.strip()\n",
    "show_wordcloud(concatenated_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d00a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2251c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Negative = data_filtered[data_filtered[\"Sentiment_Label\"] == 'Negative']\n",
    "Negative_concatenated = ''\n",
    "for i in range(Negative.shape[0]):\n",
    "    Negative_concatenated += ' ' + Negative['clean_words'].iloc[i]\n",
    "\n",
    "# to remove leading space\n",
    "Negative_concatenated = Negative_concatenated.strip()\n",
    "show_wordcloud(Negative_concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65177807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a240554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87aab7ec",
   "metadata": {},
   "source": [
    "## Conversation stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9df1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['rDate', 'Month', 'Year', 'Weekday', 'Time', 'Time-Day', 'Morning',\n",
    "       'Afternoon', 'Night', 'Sender', 'clean_msg', 'emoji','word_count_group',\n",
    "       'Sentiment_Label', 'Emosent_Label', 'is_msg', 'is_emoji','clean_words']\n",
    "\n",
    "chat = data_labeled[selected_columns]\n",
    "\n",
    "# Assuming 'Time' is the current name of the column and data_filtered is your DataFrame\n",
    "chat = chat.rename(columns={'rDate': 'date'})\n",
    "chat = chat.rename(columns={'Time': 'hour'})\n",
    "chat = chat.rename(columns={'Sentiment_Label': 'sentiment'})\n",
    "chat = chat.rename(columns={'Sender': 'username'})\n",
    "chat = chat.rename(columns={'clean_msg': 'message'})\n",
    "chat = chat.rename(columns={'Emosent_Label': 'emosent'})\n",
    "chat = chat.rename(columns={'word_count_group': 'msg_categ'})\n",
    "\n",
    "chat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83127067",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d165f2",
   "metadata": {},
   "source": [
    "## Use of emojis\n",
    "The results showed that ðŸ˜‚ Face with Tears of Joy was the most commonly used emoji, followed by ðŸ‘ Thumbs Up, ðŸ™ Folded Hands, and ðŸ¥° Smiling Face with Hearts. According to Emojipedia, these emojis suggest positive emotions, which could be assumed that the chat messages with emojis tended to be more positive in tone.\n",
    "\n",
    "Next, I analyzed the word count of the messages sent by each member to understand their communication styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32021dd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chat.groupby('username').agg({'message': 'count',\n",
    "                              'emoji': lambda x: ' '.join(set(emoji for emojis in x.dropna() for emoji in emojis))\n",
    "                              }).sort_values(by='message', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbce163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe801f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "emoji_counter = Counter()\n",
    "\n",
    "# Iterate over each message in the 'emoji' column\n",
    "for message in chat['emoji']:\n",
    "    # Check if the message is not NaN and is a string\n",
    "    if not pd.isna(message) and isinstance(message, str):\n",
    "        # Exclude \"_\" emoji and update the counter\n",
    "        emoji_counter.update(emoji for emoji in message if emoji != \"_\")\n",
    "\n",
    "# Create a DataFrame from the Counter\n",
    "emoji_df = pd.DataFrame(emoji_counter.most_common(), columns=['emoji', 'count'], index=range(1, len(emoji_counter) + 1))\n",
    "\n",
    "chat['emoji'] = chat['emoji'].replace({'ðŸ»':'ðŸ¤·'})\n",
    "chat['emoji'] = chat['emoji'].replace({'âš ':'âš ï¸'})\n",
    "\n",
    "# Display the top 20 emojis\n",
    "emoji_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a30e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat['is_emoji_empty'] = chat['emoji'].apply(lambda x: 0 if pd.isna(x) or x == '_' else 1)\n",
    "grouped_chat = chat.groupby('is_emoji_empty').size().reset_index(name='count')\n",
    "\n",
    "chat['is_emoji'] = chat['emoji'].apply(lambda x: True if x != '_' else False)\n",
    "grouped_chat = chat.groupby('is_emoji').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c84651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a pie chart using Plotly\n",
    "fig = go.Figure(data=go.Pie(\n",
    "    labels=['Chats without emoji', 'Chats with emoji'],\n",
    "    values=grouped_chat['count'],\n",
    "    hole=0.4,marker=dict(colors=['#25D366', '#075E54']),\n",
    "    title=dict(text='<b>Overall</b>', font=dict(size=16))))\n",
    "\n",
    "fig.update_traces(hoverinfo='label+value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Pie(labels=['Negative', 'Neutral', 'Positive'],\n",
    "                            values=chat.groupby('sentiment').count()[['message']].reset_index()['message'],\n",
    "                             hole=.4, marker=dict(colors=['#075E54', '#dcf8c6', '#25D366']),\n",
    "                             title=dict(text='<b>Overall</b>', font=dict(size=16))))\n",
    "\n",
    "fig.update_traces(hoverinfo='label+value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a01103",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd182e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "\n",
    "fig.add_trace(go.Pie(labels=['Negative', 'Neutral', 'Positive'],\n",
    "                     values=chat[chat.msg_categ == 'short msg'].groupby('sentiment').count()[['message']].reset_index()['message'],\n",
    "                     marker=dict(colors=['#075E54','#dcf8c6', '#25D366', ]),\n",
    "                     title=dict(text='<b>short msg</b>', font=dict(size=16))), 1, 1)\n",
    "\n",
    "fig.add_trace(go.Pie(labels=['Negative', 'Neutral', 'Positive'],\n",
    "                     values=chat[chat.msg_categ == 'regular msg'].groupby('sentiment').count()[['message']].reset_index()['message'],\n",
    "                     hole=.4, marker=dict(colors=['#075E54','#dcf8c6', '#25D366', ]),\n",
    "                     title=dict(text='<b>regular msg</b>', font=dict(size=16))), 1, 2)\n",
    "\n",
    "fig.update_traces(hole=.4, hoverinfo='label+value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa58a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "\n",
    "fig.add_trace(go.Pie(labels=['Negative', 'Neutral', 'Positive'],\n",
    "                     values=chat[chat.is_emoji_empty == 0].groupby('sentiment').count()[['message']].reset_index()['message'],\n",
    "                     marker=dict(colors=['#075E54','#dcf8c6', '#25D366', ]),\n",
    "                     title=dict(text='<b>without Emoji</b>', font=dict(size=16))), 1, 1)\n",
    "\n",
    "fig.add_trace(go.Pie(labels=['Negative', 'Neutral', 'Positive'],\n",
    "                     values=chat[chat.is_emoji_empty == 1].groupby('sentiment').count()[['message']].reset_index()['message'],\n",
    "                     hole=.4, marker=dict(colors=['#075E54','#dcf8c6', '#25D366', ]),\n",
    "                     title=dict(text='<b>with Emoji</b>', font=dict(size=16))), 1, 2)\n",
    "\n",
    "fig.update_traces(hole=.4, hoverinfo='label+value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96aa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b6e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c4611f7",
   "metadata": {},
   "source": [
    "## Message length\n",
    "Next, I analyzed the word count of the messages sent by each member to understand their communication styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e48217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whatstk import WhatsAppChat, FigureBuilder\n",
    "\n",
    "fig = FigureBuilder(chat.assign(message=chat['message'].apply(lambda x: ''.join([' ' for i in range(len(x.split())) if x != '<Media omitted>'])))\n",
    "                    ).user_msg_length_boxplot(title='User message length', xlabel=None)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d085e60f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25dc4ad2",
   "metadata": {},
   "source": [
    "## Message activity\n",
    "Looking at the conversation stats, it was pretty obvious that some members were more active than others. But, to really get what was going on in this group chat, I needed to see how often messages were being sent over time. Thus, I delved deeper to get the scoop on message activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e44bf",
   "metadata": {},
   "source": [
    "## Activity by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b974d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat['date'] = pd.to_datetime(chat['date'])\n",
    "# chat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c87f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureBuilder(chat).user_interventions_count_linechart(title=None, xlabel=None, all_users=True)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c74c4",
   "metadata": {},
   "source": [
    "## Members interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a15d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureBuilder(chat).user_interventions_count_linechart(date_mode='date', title=None, xlabel=None)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce942601",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureBuilder(chat).user_interventions_count_linechart(cumulative=True, title=None, xlabel=None)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ef5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be89ae3d",
   "metadata": {},
   "source": [
    "## Activity by hour "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3379db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat['hour'] = pd.to_datetime(chat['hour']).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ebae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(chat, index='hour', columns='Time-Day', values='message', aggfunc='count').fillna(0)\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9308fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='hour', data=chat, palette='viridis')\n",
    "plt.title('Distribution of messages')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Messages')\n",
    "plt.legend(title='', title_fontsize='12')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34072dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='hour', hue='Time-Day', data=chat, palette='viridis')\n",
    "plt.title('Distribution of messages')\n",
    "plt.xlabel('Time-Day')\n",
    "plt.ylabel('Quantity')\n",
    "plt.legend(title='Hour', title_fontsize='12')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520acbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341534a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc9f942",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(chat, index='hour', columns='Weekday', values='message', aggfunc='count').fillna(0)\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(chat, index='hour', columns='Weekday', values='message', aggfunc='count').fillna(0)\n",
    "heatmap = go.Heatmap(z=pivot.values,\n",
    "                     x=pivot.columns,\n",
    "                     y=pivot.index,\n",
    "                     hovertemplate='Interventions at %{y}-hour<extra>%{z}</extra>',\n",
    "                     colorscale='Greens')\n",
    "fig = go.Figure(data=[heatmap]).update_layout(xaxis={'categoryorder': 'array',\n",
    "                                                     'categoryarray': ['Monday', 'Tuesday', 'Wednesday',\n",
    "                                                                       'Thursday', 'Friday', 'Saturday', 'Sunday']})\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46842b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(chat, index='Time-Day', columns='Weekday', values='message', aggfunc='count').fillna(0)\n",
    "heatmap = go.Heatmap(z=pivot.values,\n",
    "                     x=pivot.columns,\n",
    "                     y=pivot.index,\n",
    "                     hovertemplate='Interventions at %{y}-Time-Day<extra>%{z}</extra>',\n",
    "                     colorscale='Greens')\n",
    "fig = go.Figure(data=[heatmap]).update_layout(xaxis={'categoryorder': 'array',\n",
    "                                                     'categoryarray': ['Monday', 'Tuesday', 'Wednesday',\n",
    "                                                                       'Thursday', 'Friday', 'Saturday', 'Sunday']})\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat['date'] = pd.to_datetime(chat['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_chat = chat.groupby('hour').size().reset_index(name='count')\n",
    "hour_chat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureBuilder(chat).user_interventions_count_linechart(\n",
    "    date_mode='weekday',\n",
    "    title=None,\n",
    "    xlabel=None).update_layout(xaxis={'tickvals': [0, 1, 2, 3, 4, 5, 6],\n",
    "    'ticktext': ['Monday', 'Tuesday', 'Wednesday','Thursday', 'Friday', 'Saturday', 'Sunday']})\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae31a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd88cd68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca7ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17d6ad05",
   "metadata": {},
   "source": [
    "## Member interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureBuilder(chat).user_message_responses_heatmap(title=None)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36c540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb69ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureBuilder(chat).user_message_responses_flow(title=None)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54169dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065c74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71932715",
   "metadata": {},
   "source": [
    "## How everyoneâ€™s feeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56903c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# + and - by user\n",
    "pivot = pd.pivot_table(chat, index='sentiment',\n",
    "                       columns='username',\n",
    "                       values='message',\n",
    "                       aggfunc='count').apply(lambda x: x/x.sum(), axis=0)\n",
    "heatmap = go.Heatmap(z=pivot.values,\n",
    "                     x=pivot.columns,\n",
    "                     y=pivot.index,\n",
    "                     hovertemplate='Interventions<extra>%{z:.2%}</extra>',\n",
    "                     colorscale='Greens')\n",
    "fig = go.Figure(data=[heatmap])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2954cc",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "After analyzing our WhatsApp group chat, it can be concluded that our group chat was a \n",
    "fun and supportive space where everyone showed appreciation for one another and had a good laugh. \n",
    "Despite a mostly neutral sentiment, the use of emojis added a positive touch. The chatâ€™s topics vary greatly, from casual banter to serious discussions, making for an engaging and diverse conversation.\n",
    "Overall, the analysis provided valuable insights into what our group chat is all about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1bc9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575ff64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bea191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4afe26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
